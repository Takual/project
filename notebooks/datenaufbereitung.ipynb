{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Datenvorverarbereitung/Stichproben und Vor-Analyse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zelle 1 - Setup und Imports:\n",
    "\n",
    "Importiert alle benötigten Bibliotheken\n",
    "Setzt grundlegende Darstellungsoptionen\n",
    "Konfiguriert den Plot-Stil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setup und Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "# Setzen der Display-Optionen für bessere Lesbarkeit\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "pd.set_option('display.width', 1000)\n",
    "\n",
    "# Warnung unterdrücken\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Plotstil festlegen (verwenden einen basic matplotlib style)\n",
    "plt.style.use('default')\n",
    "# Seaborn Plotting Style setzen\n",
    "sns.set_theme(style=\"whitegrid\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ignorieren. Nur zum Testen des Verzechnisses\n",
    "import os\n",
    "print(\"Aktuelles Arbeitsverzeichnis:\", os.getcwd())\n",
    "print(\"\\nDateien im aktuellen Verzeichnis:\")\n",
    "print(os.listdir())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Daten laden und erste Inspektion:\n",
    "\n",
    "Lädt den Datensatz\n",
    "Zeigt grundlegende Informationen wie Dimensionen und Datentypen\n",
    "Überprüft auf fehlende Werte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensionen des Datensatzes: (1428, 39)\n",
      "\n",
      "Informationen über den Datensatz:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1428 entries, 0 to 1427\n",
      "Data columns (total 39 columns):\n",
      " #   Column                                     Non-Null Count  Dtype  \n",
      "---  ------                                     --------------  -----  \n",
      " 0   video_id                                   1428 non-null   object \n",
      " 1   title                                      1428 non-null   object \n",
      " 2   publish_date                               1428 non-null   object \n",
      " 3   video_length_seconds                       1428 non-null   int64  \n",
      " 4   wiedergabezeit_minuten                     1428 non-null   int64  \n",
      " 5   durchschnittliche_wiedergabedauer          1428 non-null   float64\n",
      " 6   durchschnittliche_wiedergabedauer_prozent  1428 non-null   float64\n",
      " 7   gewonnene_abonnenten                       1428 non-null   float64\n",
      " 8   verlorene_abonnenten                       1428 non-null   int64  \n",
      " 9   aufrufe                                    1428 non-null   int64  \n",
      " 10  likes                                      1428 non-null   int64  \n",
      " 11  dislikes                                   1428 non-null   int64  \n",
      " 12  geteilte_inhalte                           1428 non-null   int64  \n",
      " 13  kommentare                                 1428 non-null   float64\n",
      " 14  audience_female_age18-24                   856 non-null    float64\n",
      " 15  audience_male_age18-24                     1140 non-null   float64\n",
      " 16  audience_female_age25-34                   1049 non-null   float64\n",
      " 17  audience_male_age25-34                     1335 non-null   float64\n",
      " 18  audience_female_age35-44                   1174 non-null   float64\n",
      " 19  audience_male_age35-44                     1370 non-null   float64\n",
      " 20  audience_female_age45-54                   1254 non-null   float64\n",
      " 21  audience_male_age45-54                     1364 non-null   float64\n",
      " 22  audience_female_age55-64                   1323 non-null   float64\n",
      " 23  audience_male_age55-64                     1370 non-null   float64\n",
      " 24  audience_female_age65-                     1352 non-null   float64\n",
      " 25  audience_male_age65-                       1372 non-null   float64\n",
      " 26  audience_female_age13-17                   27 non-null     float64\n",
      " 27  audience_male_age13-17                     138 non-null    float64\n",
      " 28  Neue Zuschauer                             1428 non-null   float64\n",
      " 29  Klicks auf Abspannelement                  1428 non-null   int64  \n",
      " 30  Klicks auf Infokartenteaser                1428 non-null   int64  \n",
      " 31  Klicks auf Infokarte                       1428 non-null   int64  \n",
      " 32  Mag ich nicht-Bewertungen                1428 non-null   int64  \n",
      " 33  Im Feed angezeigt                          1428 non-null   int64  \n",
      " 34  Impressionen                               1428 non-null   float64\n",
      " 35  Klickrate der Impressionen (%)             1428 non-null   float64\n",
      " 36  Thema                                      1428 non-null   object \n",
      " 37  Bewertung_Titel                            1428 non-null   float64\n",
      " 38  Gestaltung_Thumbnail                       1428 non-null   int64  \n",
      "dtypes: float64(22), int64(13), object(4)\n",
      "memory usage: 435.2+ KB\n",
      "None\n",
      "\n",
      "Erste Zeilen des Datensatzes:\n",
      "      video_id                                              title      publish_date  video_length_seconds  wiedergabezeit_minuten  durchschnittliche_wiedergabedauer  durchschnittliche_wiedergabedauer_prozent  gewonnene_abonnenten  verlorene_abonnenten  aufrufe  likes  dislikes  geteilte_inhalte  kommentare  audience_female_age18-24  audience_male_age18-24  audience_female_age25-34  audience_male_age25-34  audience_female_age35-44  audience_male_age35-44  audience_female_age45-54  audience_male_age45-54  audience_female_age55-64  audience_male_age55-64  audience_female_age65-  audience_male_age65-  audience_female_age13-17  audience_male_age13-17  Neue Zuschauer  Klicks auf Abspannelement  Klicks auf Infokartenteaser  Klicks auf Infokarte  Mag ich nicht-Bewertungen  Im Feed angezeigt  Impressionen  Klickrate der Impressionen (%)      Thema  Bewertung_Titel  Gestaltung_Thumbnail\n",
      "0  lVG6eRg0q5c  \"\"\"Deutsches Bier\"\" launig auf dem Donau-Hochw...  03.06.2024 15:33                   489                  138082                               51.0                                      10.62                  32.0                     1   159553    140        38               125        47.0                       0.3                     0.9                       1.5                     3.0                       4.4                     6.1                       6.3                     7.7                      12.9                    14.6                    20.2                  22.0                       NaN                     NaN         35237.0                         61                            0                     0                           38                  0      903246.0                            1.62  Sonstiges              6.5                     2\n",
      "1  v1zxksbljTw  \"Wegen Trump-Witz von RBB gefeuert: El Hotzo: ...  28.11.2024 08:22                   654                   14378                               70.0                                      10.82                   1.0                     0    12192     63        34                 8        41.0                       NaN                     0.6                       0.6                     3.2                       1.2                     5.8                       2.0                     8.4                       5.8                    18.4                    17.3                  36.7                       NaN                     NaN          1190.0                          3                            1                     0                           34                  0       26687.0                            5.34    Politik              6.5                     3\n",
      "2  kDA14tV5KyE  AfD und CDU rutschen ab, BSW gewinnt an Zuspru...  06.02.2024 18:00                   621                  324421                               71.0                                      11.54                  69.0                     8   271667    362       865               148         0.0                       0.1                     0.8                       0.4                     2.2                       1.2                     5.0                       2.5                     8.7                       7.0                    20.6                    14.9                  36.3                       NaN                     NaN         71659.0                         76                            0                     0                          865                  0      501366.0                            5.00    Politik              6.5                     2\n",
      "3  WrtzFVv8IC4  \"Designierter Grünen-Chef verbreitet \"\"leichte...  16.10.2024 11:34                  2535                   71481                              322.0                                      12.73                  17.0                     1    13293     64        41                17        30.0                       NaN                     0.8                       0.4                     2.9                       1.2                     7.4                       3.1                     9.4                       8.1                    16.8                    21.9                  28.0                       NaN                     NaN          1671.0                          2                            1                     0                           41                  0       75502.0                            5.77    Politik              6.5                     3\n",
      "4  5D1cWdr8S_k  Union baut Führung aus, AfD dahinter, FDP wäre...  24.09.2024 14:36                   944                  118639                              121.0                                      12.90                  19.0                     0    58475    230        73                18       126.0                       0.1                     1.2                       0.3                     2.8                       0.9                     5.7                       2.0                     8.8                       5.2                    20.2                    13.6                  39.2                       NaN                     NaN          2395.0                         35                            2                     0                           73                  0      333528.0                            5.15    Politik              6.5                     3\n",
      "\n",
      "Anzahl fehlender Werte pro Spalte:\n",
      "video_id                                        0\n",
      "title                                           0\n",
      "publish_date                                    0\n",
      "video_length_seconds                            0\n",
      "wiedergabezeit_minuten                          0\n",
      "durchschnittliche_wiedergabedauer               0\n",
      "durchschnittliche_wiedergabedauer_prozent       0\n",
      "gewonnene_abonnenten                            0\n",
      "verlorene_abonnenten                            0\n",
      "aufrufe                                         0\n",
      "likes                                           0\n",
      "dislikes                                        0\n",
      "geteilte_inhalte                                0\n",
      "kommentare                                      0\n",
      "audience_female_age18-24                      572\n",
      "audience_male_age18-24                        288\n",
      "audience_female_age25-34                      379\n",
      "audience_male_age25-34                         93\n",
      "audience_female_age35-44                      254\n",
      "audience_male_age35-44                         58\n",
      "audience_female_age45-54                      174\n",
      "audience_male_age45-54                         64\n",
      "audience_female_age55-64                      105\n",
      "audience_male_age55-64                         58\n",
      "audience_female_age65-                         76\n",
      "audience_male_age65-                           56\n",
      "audience_female_age13-17                     1401\n",
      "audience_male_age13-17                       1290\n",
      "Neue Zuschauer                                  0\n",
      "Klicks auf Abspannelement                       0\n",
      "Klicks auf Infokartenteaser                     0\n",
      "Klicks auf Infokarte                            0\n",
      "Mag ich nicht-Bewertungen                     0\n",
      "Im Feed angezeigt                               0\n",
      "Impressionen                                    0\n",
      "Klickrate der Impressionen (%)                  0\n",
      "Thema                                           0\n",
      "Bewertung_Titel                                 0\n",
      "Gestaltung_Thumbnail                            0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Zelle 2: Daten laden und erste Inspektion\n",
    "# Daten einlesen mit zusätzlichen Parametern für robusteres Parsing\n",
    "# df = pd.read_csv('https://raw.githubusercontent.com/Takual/project/refs/heads/main/data/raw/videos_ab_60s.csv', \n",
    "#                 encoding='utf-8',\n",
    "#                 sep=';',  # Semikolon als Trennzeichen\n",
    "#                 decimal=',',  # Komma als Dezimaltrennzeichen\n",
    "#                 thousands='.',  # Punkt als Tausendertrennzeichen\n",
    "#                on_bad_lines='warn')  # Warnung bei problematischen Zeilen\n",
    "\n",
    "#hier die Version, wenn auch die Live-Themen dabei sein sollen\n",
    "#df = pd.read_csv('../data/raw/videos_ohneshorts.csv', encoding='utf-8', sep=';', decimal=',', thousands='.')\n",
    "# hier der Link zur Datendatei ohne Live-Themen\n",
    "df = pd.read_csv('../data/raw/videos_ohnelive_ohneshorts.csv', encoding='utf-8', sep=';', decimal=',', thousands='.')\n",
    "\n",
    "# Überblick über den Datensatz\n",
    "print(\"Dimensionen des Datensatzes:\", df.shape)\n",
    "print(\"\\nInformationen über den Datensatz:\")\n",
    "print(df.info())\n",
    "\n",
    "# Erste Zeilen anzeigen\n",
    "print(\"\\nErste Zeilen des Datensatzes:\")\n",
    "print(df.head())\n",
    "\n",
    "# Überprüfung auf fehlende Werte\n",
    "print(\"\\nAnzahl fehlender Werte pro Spalte:\")\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ignore \n",
    "(Hier noch ein Überblick über die Spalten und die Datenstruktur, auftgeteilt in Gruppen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def show_column_groups_table(df):\n",
    "    def shorten_column_name(name, max_length=30):\n",
    "        \"\"\"Kürzt lange Spaltennamen sinnvoll\"\"\"\n",
    "        if len(name) <= max_length:\n",
    "            return name\n",
    "        \n",
    "        # Versuche, sinnvolle Abkürzungen zu erstellen\n",
    "        words = name.split('_')\n",
    "        if len(words) > 1:\n",
    "            # Nehme Anfangsbuchstaben und letzte Wörter\n",
    "            shortened = ''.join(word[0].upper() for word in words[:-1]) + '_' + words[-1]\n",
    "            return shortened[:max_length]\n",
    "        \n",
    "        # Für einen langen Namen ohne Unterstrich\n",
    "        return name[:15] + '...' + name[-10:]\n",
    "\n",
    "    # Gruppiere Spalten nach Datentyp\n",
    "    numeric_cols = df.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "    datetime_cols = df.select_dtypes(include=['datetime64']).columns.tolist()\n",
    "    categorical_cols = df.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "    boolean_cols = df.select_dtypes(include=['bool']).columns.tolist()\n",
    "    \n",
    "    # Kürze Spaltennamen\n",
    "    numeric_cols_short = [shorten_column_name(col) for col in numeric_cols]\n",
    "    datetime_cols_short = [shorten_column_name(col) for col in datetime_cols]\n",
    "    categorical_cols_short = [shorten_column_name(col) for col in categorical_cols]\n",
    "    boolean_cols_short = [shorten_column_name(col) for col in boolean_cols]\n",
    "    \n",
    "    # Erstelle einen DataFrame für die Übersicht\n",
    "    column_groups = pd.DataFrame({\n",
    "        'Datentyp': [\n",
    "            'Numerische Spalten', \n",
    "            'Datetime Spalten', \n",
    "            'Kategorische/Text Spalten',\n",
    "            'Boolesche Spalten'\n",
    "        ],\n",
    "        'Spalten': [\n",
    "            ', '.join(numeric_cols_short) if numeric_cols_short else '-',\n",
    "            ', '.join(datetime_cols_short) if datetime_cols_short else '-',\n",
    "            ', '.join(categorical_cols_short) if categorical_cols_short else '-',\n",
    "            ', '.join(boolean_cols_short) if boolean_cols_short else '-'\n",
    "        ],\n",
    "        'Anzahl': [\n",
    "            len(numeric_cols),\n",
    "            len(datetime_cols),\n",
    "            len(categorical_cols),\n",
    "            len(boolean_cols)\n",
    "        ],\n",
    "        'Original Namen': [\n",
    "            ', '.join(numeric_cols) if numeric_cols else '-',\n",
    "            ', '.join(datetime_cols) if datetime_cols else '-',\n",
    "            ', '.join(categorical_cols) if categorical_cols else '-',\n",
    "            ', '.join(boolean_cols) if boolean_cols else '-'\n",
    "        ]\n",
    "    })\n",
    "    \n",
    "    # Formatiere die Ausgabe\n",
    "    pd.set_option('display.max_colwidth', None)\n",
    "    print(column_groups)\n",
    "    \n",
    "    # Zusätzliche Gesamtinformationen\n",
    "    print(f\"\\nGesamtanzahl Spalten: {len(df.columns)}\")\n",
    "    \n",
    "    return column_groups\n",
    "\n",
    "# Funktion aufrufen\n",
    "column_overview = show_column_groups_table(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Datenbereinigung und Transformation:\n",
    "\n",
    "Konvertiert Datums-Strings in datetime-Objekte\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zelle 3: Datenbereinigung\n",
    "# Datumskonvertierung mit verbesserte Fehlerbehandlung\n",
    "if 'publish_date' in df.columns:\n",
    "    df['publish_date'] = pd.to_datetime(df['publish_date'], format='%d.%m.%Y %H:%M', errors='coerce')\n",
    "    df['publish_hour'] = df['publish_date'].dt.hour\n",
    "    df['publish_weekday'] = df['publish_date'].dt.dayofweek\n",
    "\n",
    "print(\"Datentypen nach Bereinigung:\")\n",
    "print(df.dtypes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature Engineering\n",
    "Diese Zelle bereitet die Features für die Modellierung vor. Ein wichtiger Schritt ist die Umwandlung der kategorialen Variable \"Thema\" in Dummy-Variablen oder Indikatorvariable. Dabei wird jede Kategorie (wie \"Politik\", \"Wirtschaft\" etc.) in eine eigene Spalte umgewandelt, die nur 0 und 1 enthält. Dies ist notwendig, um Multikollinarität zu vermeiden. Außerdem werden hier die Ziel- und Prädiktorvariablen definiert, die für die späteren Modelle verwendet werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zelle 4: Feature Engineering\n",
    "\n",
    "# Zielvariablen definieren\n",
    "target_columns = ['durchschnittliche_wiedergabedauer', 'aufrufe', 'Klickrate der Impressionen (%)']\n",
    "\n",
    "# Features für die Modellierung auswählen\n",
    "# Schließen Sie Zielvariablen und die Themenspalte aus\n",
    "feature_columns = [col for col in df.columns if col not in target_columns + ['Thema']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Skalierung der Features NICHT MEHR NUTZEN\n",
    "In dieser Zelle werden die numerischen Features standardisiert. Dies ist wichtig, weil die verschiedenen Features sehr unterschiedliche Größenordnungen haben (z.B. Video-Länge in Sekunden vs. Bewertungen von 1-10). Die Standardisierung sorgt dafür, dass alle numerischen Features einen Mittelwert von 0 und eine Standardabweichung von 1 haben. Dies verhindert, dass Features mit großen Zahlen das Modell unverhältnismäßig stark beeinflussen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zelle 5: Selektive Skalierung der Features\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Scaler für bestimmte numerische Features\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Spalten, die skaliert werden sollten (große Wertebereiche)\n",
    "columns_to_scale = [\n",
    "    'video_length_seconds', 'wiedergabezeit_minuten', 'durchschnittliche_wiedergabedauer',\n",
    "    'aufrufe', 'likes', 'dislikes', 'geteilte_inhalte', 'kommentare', 'Impressionen'\n",
    "]\n",
    "\n",
    "# Skalieren nur dieser Spalten\n",
    "df[columns_to_scale] = scaler.fit_transform(df[columns_to_scale])\n",
    "\n",
    "print(\"\\nFeature-Columns:\", feature_columns)\n",
    "print(\"\\nNumerische Features, die skaliert wurden:\", columns_to_scale)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train-Test-Split (ALT)\n",
    "Diese Zelle teilt die Daten in drei Teile auf: Trainings-, Validierungs- und Testdaten. Der Trainingsdatensatz (60%) wird verwendet, um das Modell zu trainieren. Der Validierungsdatensatz (20%) dient dazu, die Modellleistung während des Trainings zu überprüfen und  zu optimieren. Der Testdatensatz (20%) wird erst ganz am Ende verwendet, um die finale Modellperformance zu evaluieren."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zelle 6: Train-Test-Split\n",
    "# Features und Targets separieren\n",
    "X = df[feature_columns]\n",
    "y = df[target_columns]\n",
    "\n",
    "# Erste Aufteilung in temporäres Training+Validierung und Test\n",
    "X_temp, X_test, y_temp, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Zweite Aufteilung des temporären Sets in Training und Validierung\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_temp, y_temp, test_size=0.25, random_state=42  # 0.25 x 0.8 = 0.2\n",
    ")\n",
    "\n",
    "print(\"\\nDimensionen der Datensätze:\")\n",
    "print(f\"Training: {X_train.shape}, {y_train.shape}\")\n",
    "print(f\"Validierung: {X_val.shape}, {y_val.shape}\")\n",
    "print(f\"Test: {X_test.shape}, {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Neuer Train-Test-Split mit nachfolgender Dummy\n",
    "hier werden die Daten gesplitet mit Stratifizierter Aufteilung. IM ursprünglichen Ansatz war die Aufteilung der Themen nicht optimal, da es doch Themen gibt, die stärker angeschaut werden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zelle 6: Korrekter Train-Test-Split\n",
    "# Zielvariablen definieren\n",
    "target_columns = ['durchschnittliche_wiedergabedauer', 'aufrufe', 'Klickrate der Impressionen (%)']\n",
    "\n",
    "# Feature-Spalten exkl. Target und Thema\n",
    "feature_columns = [col for col in df.columns if col not in target_columns + ['Thema']]\n",
    "\n",
    "# Features und Targets separieren\n",
    "X = df[feature_columns]\n",
    "y = df[target_columns]\n",
    "\n",
    "# Erste Aufteilung mit Stratifizierung über originale Themenspalte\n",
    "X_train_val, X_test, y_train_val, y_test = train_test_split(\n",
    "    X, \n",
    "    y, \n",
    "    stratify=df['Thema'], \n",
    "    test_size=0.2, \n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Zweite Aufteilung von Training/Validierung\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_train_val, \n",
    "    y_train_val, \n",
    "    stratify=df.loc[X_train_val.index, 'Thema'], \n",
    "    test_size=0.25, \n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Themenverteilung prüfen\n",
    "print(\"Themenverteilung:\")\n",
    "print(\"Original:    \", df['Thema'].value_counts(normalize=True))\n",
    "print(\"Training:    \", df.loc[X_train.index, 'Thema'].value_counts(normalize=True))\n",
    "print(\"Validation:  \", df.loc[X_val.index, 'Thema'].value_counts(normalize=True))\n",
    "print(\"Test:        \", df.loc[X_test.index, 'Thema'].value_counts(normalize=True))\n",
    "\n",
    "# Dummy-Variablen separat für jeden Datensatz\n",
    "def create_theme_dummies(X, df_original):\n",
    "    theme_dummies = pd.get_dummies(df_original.loc[X.index, 'Thema'], prefix='theme')\n",
    "    return pd.concat([X, theme_dummies], axis=1)\n",
    "\n",
    "X_train = create_theme_dummies(X_train, df)\n",
    "X_val = create_theme_dummies(X_val, df)\n",
    "X_test = create_theme_dummies(X_test, df)\n",
    "\n",
    "# Aktualisierte Feature-Columns\n",
    "feature_columns = [col for col in X_train.columns if col not in target_columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Daten speichern\n",
    "In der letzten Zelle werden alle verarbeiteten Daten gespeichert, damit sie in späteren Analysen wieder verwendet werden können. Die Daten werden sowohl im Pickle-Format (für Python-spezifische Objekte wie den Scaler) als auch als CSV-Dateien gespeichert. CSVs sind dabei besonders nützlich für schnelle Inspektionen der Daten. Wichtig ist auch, dass der Scaler mitgespeichert wird, damit neue Daten auf die gleiche Weise transformiert werden können.\n",
    "Dies stellt sicher, dass wir einen sauberen, reproduzierbaren Datensatz für unsere Analysen haben und dass alle Transformationen konsistent auf zukünftige Daten angewendet werden können."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Daten wurden erfolgreich gespeichert in 'data/processed/processed_data.pkl'\n"
     ]
    }
   ],
   "source": [
    "# Zelle 7: Daten speichern\n",
    "# Ordner für verarbeitete Daten erstellen\n",
    "if not os.path.exists('data/processed'):\n",
    "    os.makedirs('data/processed')\n",
    "\n",
    "# Daten als Pickle-Datei speichern\n",
    "with open('../data/processed/processed_data.pkl', 'wb') as f:\n",
    "    pickle.dump({\n",
    "        'X_train': X_train,\n",
    "        'X_val': X_val,\n",
    "        'X_test': X_test,\n",
    "        'y_train': y_train,\n",
    "        'y_val': y_val,\n",
    "        'y_test': y_test,\n",
    "        #'scaler': scaler,\n",
    "        'feature_columns': feature_columns,\n",
    "        'target_columns': target_columns\n",
    "    }, f)\n",
    "\n",
    "print(\"\\nDaten wurden erfolgreich gespeichert in 'data/processed/processed_data.pkl'\")\n",
    "\n",
    "# Optional: Auch als CSV speichern für einfachere Inspektion\n",
    "X_train.to_csv('../data/processed/X_train.csv', sep=';', decimal=',', index=False)\n",
    "y_train.to_csv('../data/processed/y_train.csv', sep=';', decimal=',', index=False)\n",
    "X_val.to_csv('../data/processed/X_val.csv', sep=';', decimal=',', index=False)\n",
    "y_val.to_csv('../data/processed/y_val.csv', sep=';', decimal=',', index=False)\n",
    "X_test.to_csv('../data/processed/X_test.csv', sep=';', decimal=',', index=False)\n",
    "y_test.to_csv('../data/processed/y_test.csv', sep=';', decimal=',', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: Auch als CSV speichern für einfachere Inspektion\n",
    "X_train.to_csv('../data/processed/X_train.csv', sep=';', decimal=',', index=False)\n",
    "y_train.to_csv('../data/processed/y_train.csv', sep=';', decimal=',', index=False)\n",
    "X_val.to_csv('../data/processed/X_val.csv', sep=';', decimal=',', index=False)\n",
    "y_val.to_csv('../data/processed/y_val.csv', sep=';', decimal=',', index=False)\n",
    "X_test.to_csv('../data/processed/X_test.csv', sep=';', decimal=',', index=False)\n",
    "y_test.to_csv('../data/processed/y_test.csv', sep=';', decimal=',', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

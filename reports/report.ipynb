{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction and data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Die Bedeutung von YouTube für Nachrichtenmedien\n",
    "\n",
    "YouTube hat sich in den letzten Jahren zu einer der wichtigsten Plattformen für den Konsum von Videoinhalten entwickelt. Insbesondere für Nachrichtenmedien wie ntv ist die Plattform zu einem unverzichtbaren Kanal geworden, um ihre Zielgruppe zu erreichen. Die Analyse der Performance von YouTube-Videos und das Verständnis der Faktoren, die zum Erfolg einzelner Beiträge führen, sind dabei von entscheidender Bedeutung für die strategische Ausrichtung des Kanals.\n",
    "\n",
    "Für Nachrichtenmedien stellt sich dabei die besondere Herausforderung, dass sie einerseits journalistischen Qualitätsstandards gerecht werden müssen, andererseits aber auch die Mechanismen der Plattform verstehen und nutzen müssen, um ihre Inhalte erfolgreich zu platzieren. Die vorliegende Analyse soll dazu beitragen, diese Balance besser zu verstehen und zu optimieren.\n",
    "\n",
    "### Forschungsfrage und Hypothesen\n",
    "\n",
    "Die zentrale Forschungsfrage dieser Analyse lautet: Welche Faktoren beeinflussen die Performance von Videos auf dem ntv YouTube-Kanal und wie können diese Erkenntnisse genutzt werden, um die Content-Strategie zu optimieren?\n",
    "\n",
    "Dabei werden drei zentrale Hypothesen untersucht: Erstens wird angenommen, dass Videos zu bestimmten Themengebieten wie dem Ukrainekrieg im Durchschnitt mehr Aufrufe und eine längere Wiedergabedauer erzielen als Videos zu anderen Themen. Zweitens wird vermutet, dass die Art der Thumbnail-Gestaltung, insbesondere die prominente Platzierung bekannter Experten, einen signifikanten Einfluss auf die Klickrate hat. Die dritte Hypothese besagt, dass eine höhere Bewertung des Videotitels positiv mit der Anzahl der Aufrufe und der Wiedergabedauer korreliert.\n",
    "\n",
    "### Datengrundlage und Erhebungsprozess\n",
    "\n",
    "Der analysierte Datensatz umfasst etwa 2500 Videos, die im Jahr 2024 bis Mitte November auf dem ntv YouTube-Kanal veröffentlicht wurden. Die Datenerhebung gestaltete sich dabei als komplexer Prozess, der verschiedene Quellen und Methoden kombiniert. Während grundlegende Metriken wie Aufrufe, Likes und Kommentare über die YouTube Analytics API bezogen werden können, sind spezielle Metriken wie die Klickrate der Impressionen nur durch manuelle Extraktion aus dem YouTube Studio Backend verfügbar. Dies macht die Datensammlung zu einem aufwändigen Prozess, der sowohl automatisierte als auch manuelle Schritte erfordert.\n",
    "\n",
    "Zusätzlich zu den von YouTube bereitgestellten Metriken wurden weitere Kategorisierungen und Bewertungen vorgenommen. Die Videos wurden nach ihren Themenbereichen kategorisiert (Politik, Wirtschaft, Krieg, Sonstiges, Bilder, Live). Die Thumbnail-Gestaltung wurde nach einem dreistufigen System bewertet, das insbesondere die Präsenz und Positionierung wichtiger Persönlichkeiten berücksichtigt. Die Kategorie \"3\" gab es bei Thumbnails die eine Kombination von Gesicht und Titel \n",
    "\n",
    "<img src=\"../references/images/kat3.jpg\" width=\"300\" alt=\"Kategorie 3 Visualisierung\"/>\n",
    "\n",
    " besonders präsent ist. Die Kategorie \"2\" gab es, wenn eines von beiden vorhanden war:\n",
    " \n",
    "<img src=\"../references/images/kat2.jpg\" width=\"300\" alt=\"Kategorie 3 Visualisierung\"/>\n",
    "\n",
    "  Entweder ein normales Bild + präsenten Tiel oder präsentes Gesicht. Eine \"1\" wurde für Thumbnails vergeben, die keine besonderen Merkmale aufgewiesen haben. \n",
    "  \n",
    "  <img src=\"../references/images/kat1.jpg\" width=\"300\" alt=\"Kategorie 3 Visualisierung\"/>\n",
    "  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Automatische Bewertung Thumbnails und Titel\n",
    "  In der Datei \"youtube Daten abrufen Test2.ipynb\" ist auch ein Code abgelegt, der über \"Google Vision AI\" eine Bewertung der Thumnbails nach diesen Kategorien erfolgen soll. Leider war hier die Parameter zu ungenau. Eine Verbesserung des Systems wäre für das Projekt zu aufwendig und teuer gewesen. Hier müsste noch mehr Aufwand betrieben werden oder ein eigenes Modell trainiert werden. Das wäre die Aufgabe für ein neues Projekt.\n",
    "  Für die Bewertung der Videotitel wurde ein KI-gestütztes System entwickelt, das die Titel nach SEO-Kriterien auf einer Skala von 0.0 bis 10,0 bewertet. Dabei wurden durch die KI Bewertungen zwischen 4,5 und 8,5 vorgenommen. Als KI wurde ChatGPT per API genutzt. Der Code und auch der Prompt dafür ist in der Datei youtube Daten abrufen Test2.ipynb abgelegt.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class YouTubeSEOScorer:\n",
    "    def __init__(self, api_key: str, model: str = \"gpt-3.5-turbo\"):\n",
    "        self.model = model\n",
    "        self.client = OpenAI(api_key=api_key)\n",
    "        self.checkpoint_manager = CheckpointManager()\n",
    "        \n",
    "        self.system_prompt = \"\"\"Du bist ein YouTube SEO Experte, spezialisiert auf Nachrichtenkanäle. \n",
    "        Bewerte den YouTube-Titel nach folgenden Kriterien und vergib eine Gesamtpunktzahl von 0-10. \n",
    "        WICHTIG: Gib NUR die Gesamtpunktzahl als einzelne Zahl zurück, OHNE Text oder Erklärungen.\n",
    "        Beispiele korrekter Antworten:\n",
    "        7,5\n",
    "        8,0\n",
    "        6,5\n",
    "        \n",
    "        Bewerte nach diesen Kriterien:\n",
    "\n",
    "        1. Titel-Optimierung (max. 2 Punkte)\n",
    "        - Länge zwischen 40-70 Zeichen (+0.5)\n",
    "        - Hauptkeyword in den ersten 3-4 Wörtern (+0.5)\n",
    "        - Klare Struktur mit natürlicher Lesefluss (+0.5)\n",
    "        - Verwendung von Trennzeichen (|, -, :) wo sinnvoll (+0.5)\n",
    "\n",
    "        2. Nachrichtenwert & Aktualität (max. 2 Punkte)\n",
    "        - Klare Vermittlung der Nachrichtenrelevanz (+0.5)\n",
    "        - Zeitliche Einordnung wenn relevant (+0.5)\n",
    "        - Balance zwischen Aktualität und Evergreen-Potenzial (+0.5)\n",
    "        - Korrekte Priorisierung der Information (+0.5)\n",
    "\n",
    "        3. Keyword-Optimierung (max. 2 Punkte)\n",
    "        - Verwendung relevanter Nachrichtenkeywords (+0.5)\n",
    "        - Natürliche Integration von Suchbegriffen (+0.5)\n",
    "        - LSI Keywords / thematisch verwandte Begriffe (+0.5)\n",
    "        - Vermeidung von Keyword-Stuffing (+0.5)\n",
    "\n",
    "        4. Zielgruppen-Ansprache (max. 2 Punkte)\n",
    "        - Verständliche Sprache für Nachrichtenpublikum (+0.5)\n",
    "        - Seriosität und Professionalität (+0.5)\n",
    "        - Klare Themenankündigung (+0.5)\n",
    "        - Zielgruppengerechte Formulierung (+0.5)\n",
    "\n",
    "        5. Technische Optimierung (max. 2 Punkte)\n",
    "        - Keine übermäßige Großschreibung (+0.5)\n",
    "        - Korrekte Zeichensetzung (+0.5)\n",
    "        - Keine Spam-Taktiken oder Clickbait (+0.5)\n",
    "        - Mobile-freundliche Länge & Format (+0.5)\n",
    "\n",
    "        WICHTIG - FORMAT DER ANTWORT:\n",
    "        - Gib ausschließlich eine einzelne Dezimalzahl zurück\n",
    "        - Verwende ein Komma als Dezimaltrennzeichen\n",
    "        - Keine Erklärungen oder zusätzlicher Text\n",
    "        - Keine Aufschlüsselung der Einzelkriterien\n",
    "        \n",
    "        Beispiele korrekter Antworten:\n",
    "        7,5\n",
    "        8,0\n",
    "        6,5\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Zentrale Metriken und ihre Bedeutung für einen Nachrichtenkanal\n",
    "\n",
    "Für die Analyse wurden drei zentrale Zielvariablen identifiziert, die für Nachrichtenmedien auf YouTube von besonderer Bedeutung sind:\n",
    "\n",
    "Die **durchschnittliche Wiedergabedauer** ist besonders für Nachrichtenformate relevant, da sie Aufschluss darüber gibt, wie gut es gelingt, komplexe Sachverhalte für die YouTube-Zielgruppe aufzubereiten. Anders als bei traditionellen TV-Nachrichten, wo Zuschauer tendenziell das gesamte Format konsumieren, ist die Haltedauer auf YouTube ein kritischer Erfolgsfaktor. Sie beeinflusst direkt, wie häufig ein Video vom Algorithmus anderen Nutzern vorgeschlagen wird. So zeigen erfolgreiche Videos des ntv-Kanals, dass besonders Live-Berichterstattungen zu wichtigen Ereignissen, wie beispielsweise die Iran-Angriffe auf Israel, überdurchschnittliche Wiedergabedauern erzielen. Bei diesen Events bleiben Zuschauer oft über 10 Minuten am Video, während der Durchschnitt bei Nachrichtenvideos bei etwa 4-5 Minuten liegt.\n",
    "\n",
    "Die Anzahl der **Aufrufe** ist für Nachrichtenkanäle nicht nur eine reine Reichweitenkennzahl, sondern auch ein Indikator für die gesellschaftliche Relevanz ihrer Berichterstattung. Im hart umkämpften Nachrichtenmarkt auf YouTube, wo etablierte Medien mit einer Vielzahl alternativer Informationsquellen konkurrieren, sind hohe Aufrufzahlen zudem entscheidend für die Monetarisierung und damit die Finanzierung hochwertiger journalistischer Arbeit. Dabei spielen sowohl die Bekanntheit der Personen als auch die Aktualität und Relevanz der Themen eine entscheidende Rolle.\n",
    "\n",
    "Die **Klickrate der Impressionen** hat für Nachrichtenmedien eine besondere strategische Bedeutung. Sie zeigt, wie gut es gelingt, in der Informationsflut von YouTube die Aufmerksamkeit potenzieller Zuschauer zu gewinnen, ohne dabei in reißerische oder irreführende Darstellungen zu verfallen. Erfolgreiche Beispiele aus dem ntv-Kanal demonstrieren, dass Videos mit klar erkennbaren Experten im Thumbnail und prägnanten, aber sachlichen Titeln Klickraten von über 10% erreichen können - deutlich über dem Durchschnitt von etwa 4-5%. Besonders erfolgreich sind dabei Thumbnails, die bekannte Persönlichkeiten in emotionalen Momenten oder bei markanten Aussagen zeigen, kombiniert mit kurzen, prägnanten Headlines.\n",
    "\n",
    "***Limitationen und Herausforderungen***\n",
    "\n",
    "Bei der Analyse müssen einige wichtige Einschränkungen berücksichtigt werden. Die teilweise notwendige manuelle Datenextraktion erhöht das Risiko von Fehlern und macht den Prozess zeitaufwändig. Die Kategorisierung der Themen und die Bewertung der Thumbnails enthalten zwangsläufig subjektive Elemente, auch wenn versucht wurde, diese durch klare Kriterien zu minimieren. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kennzahlen und Ihre Bedeutung\n",
    "Im YouTube-Universum sind die Begriffe „Impressions“, „Klickrate der Impressions“ und „Views“ zentrale Kennzahlen, die häufig für die Performance-Analyse eines Channels herangezogen werden. Hier eine kurze Erklärung:\n",
    "### 1. Impressions (Sichtkontakte)\n",
    "\n",
    "- **Was bedeutet das?**  \n",
    "  Impressions geben an, wie oft ein Thumbnail (Vorschaubild) eines Videos auf YouTube den Nutzer*innen angezeigt wurde. Dabei spielt es keine Rolle, ob das Video letztendlich angeklickt und angesehen wird – jede einzelne Einblendung des Thumbnails in den Suchergebnissen, den Empfehlungen oder auf anderen YouTube-Oberflächen zählt als Impression.\n",
    "\n",
    "- **Wozu dient diese Kennzahl?**  \n",
    "  \\- Sie zeigt das Potenzial für Reichweite: Wie viele Leute _könnten_ das Video sehen (und ggf. anklicken)?  \n",
    "  \\- Je höher die Impressions, desto mehr Nutzer*innen wurde das Video theoretisch präsentiert.\n",
    "\n",
    "---\n",
    "\n",
    "### 2. Klickrate der Impressions (Impression Click-Through-Rate, CTR)\n",
    "\n",
    "- **Was bedeutet das?**  \n",
    "  Die Klickrate (CTR) ist der prozentuale Anteil der Impressions, bei denen tatsächlich auf das Video geklickt wurde. Anders ausgedrückt: Wenn dein Thumbnail 100 Mal angezeigt wird und 10 Mal geklickt wird, beträgt die Klickrate 10 %.  \n",
    "\n",
    "  \\[\n",
    "  \\text{Klickrate der Impressions} = \\frac{\\text{Klicks auf das Video}}{\\text{Impressions}} \\times 100\\% \n",
    "  \\]\n",
    "\n",
    "- **Wozu dient diese Kennzahl?**  \n",
    "  \\- Sie ist ein guter Indikator dafür, wie „anziehend“ der Titel und das Thumbnail deines Videos sind.  \n",
    "  \\- Eine niedrige Klickrate kann bedeuten, dass du das Video zwar oft ausgespielt bekommst (also viele Impressions), aber die Nutzer*innen sich nicht für den Klick entscheiden.  \n",
    "  \\- Eine höhere Klickrate deutet darauf hin, dass das Vorschaubild und der Titel des Videos besonders ansprechend sind und Nutzer*innen zum Anschauen animieren.\n",
    "\n",
    "---\n",
    "\n",
    "### 3. Views (Aufrufe)\n",
    "\n",
    "- **Was bedeutet das?**  \n",
    "  Views zählen, wie oft ein Video tatsächlich angesehen wurde – also wie oft jemand den Abspielknopf drückt (und das Video mindestens für eine gewisse Zeit ansieht). Die konkrete Definition, wann ein „View“ gezählt wird, hängt von YouTube-internen Kriterien ab (z. B. Mindestwiedergabedauer), sodass nicht sofort jeder Aufruf in Echtzeit als View erscheint.\n",
    "\n",
    "- **Wozu dient diese Kennzahl?**  \n",
    "  \\- Views sind wohl das bekannteste Maß für den Erfolg eines Videos.  \n",
    "  \\- Zeigt dir, wie oft dein Content tatsächlich konsumiert wurde.  \n",
    "  \\- Zusammen mit weiteren Daten (z. B. Wiedergabedauer, Zuschauerbindung) bekommst du ein Bild davon, wie interessant die Inhalte sind und wie lange die Zuschauer*innen dabeibleiben.\n",
    "\n",
    "---\n",
    "\n",
    "### Wichtig zu wissen\n",
    "- **Zusammenspiel der Kennzahlen**:  \n",
    "  \\- Hohe Impressions, aber niedrige Klickrate = Zeichen, dass das Video zwar vielen Nutzer*innen angezeigt wird, aber das Thumbnail/Titel nicht zum Klicken motiviert.  \n",
    "  \\- Niedrige Impressions, aber hohe Klickrate = Zeichen, dass das Video in der Zielgruppe, in der es ausgespielt wird, gut ankommt, aber insgesamt noch nicht genug Reichweite erzielt.  \n",
    "  \\- Views und Klickrate hängen indirekt zusammen. Eine höhere Klickrate führt in der Regel zu mehr Views – sofern YouTube das Video möglichst oft als Impression ausspielt.\n",
    "\n",
    "- **Video-Optimierung**:  \n",
    "  \\- Experimentiere mit Thumbnails, Titel und Beschreibungen, um eine gute Balance zwischen **vielen Impressions** und einer **hohen Klickrate** zu erreichen.  \n",
    "  \\- Eine gute Zuschauerbindung (Retention) ist ebenfalls wichtig, weil YouTube-Algorithmen Videos mit hoher Zuschauerzufriedenheit häufiger vorschlagen.\n",
    "\n",
    "- **Gerätenutzung**:    \n",
    "  \\- Für die Bewertung der Ergebnisse könnte auch wichtig sein, auf welchen Geräten die User die Youtube-Vides schauen:\n",
    "\n",
    "    <span style=\"color: red; font-weight: bold;\">  Handy: 61,9 %, Computer: 15,6 %, TV: 13,6 %, Tablet: 8,8 % </span>\n",
    "\n",
    "  \\- Oder das Geschlecht und Alter der User:\n",
    "\n",
    "    <span style=\"color: red; font-weight: bold;\">  Männlich 80%, Alter: 55+ 61 %, 25 bis 55: 35 % </span>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datenvorverarbeitung"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Im Notebook **Datenaufbereitung** werden die RAW-Daten geladen und in verschiedenen Schritten aufbereitet. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScale\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "# Setzen der Display-Optionen für bessere Lesbarkeit\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "pd.set_option('display.width', 1000)\n",
    "\n",
    "# Warnung unterdrücken\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Plotstil festlegen (verwenden einen basic matplotlib style)\n",
    "plt.style.use('default')\n",
    "# Seaborn Plotting Style setzen\n",
    "sns.set_theme(style=\"whitegrid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Schlussfolgerungen der bisherigen Datenanalyse und Datenvorverarbeitung\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **1. Datenstruktur und Vorbereitung**\n",
    "- Der Datensatz enthält sowohl numerische als auch kategoriale Merkmale.\n",
    "- Die Zielvariablen zeigen starke Rechtsschiefe mit vielen niedrigen und wenigen extrem hohen Werten.\n",
    "\n",
    "<img src=\"../references/images/erste analyse der Zielvariablen.jpg\" width=\"600\" alt=\"Verteilung Zielvariablen\"/>\n",
    "\n",
    "- Merkmale wie **\"video_id\" wurden als Identifikationsspalten ausgeschlossen, da sie keinen direkten Einfluss auf die Vorhersage der Aufrufzahlen haben. \n",
    "\n",
    "### **2. Bewertung der Variablen**\n",
    "- **Bewertung_Titel:**\n",
    "  - Diese Variable wurde auf einer Skala von 0 bis 10 vergeben und sollte daher nicht skaliert werden, um die interpretierbare Einteilung (z. B. schlechte, durchschnittliche und gute Bewertungen) beizubehalten.\n",
    "  - Die Verteilung der Werte zeigte eine starke Konzentration auf einige wenige Werte. Die reine SEO-Bewertung scheint nicht sinnvoll, da die KollegInnen bereits auf einem hohen Noveau arbeiten und die Bewertung zwischen 6 und 8 laufen. \n",
    "\n",
    "- **Gestaltung_Thumbnail:**\n",
    "  - Diese Variable wurde in den Werten 1, 2 und 3 vergeben und spiegelt eine Einteilung in Kategorien wider (z. B. schlecht, neutral, gut).\n",
    "  - Auch hier wurde festgestellt, dass eine Standardisierung nicht sinnvoll ist, da es sich um feste Kategorien handelt.\n",
    "\n",
    "### **3. Zusammenhänge zwischen Prädiktoren und Zielvariable**\n",
    "- **Themenzugehörigkeit:**\n",
    "  - Das Thema `Krieg` zeigte einen deutlichen Einfluss auf die Aufrufzahlen. Videos mit diesem Thema hatten im Vergleich zu anderen Themen höhere Median-Aufrufzahlen und eine breite Streuung.\n",
    "  - \n",
    "<img src=\"../references/images/boxplot Krieg_Aufrufe.JPG\" width=\"400\" alt=\"Boxplot Krieg vs. Aufrufe\"/>\n",
    "\n",
    "  - Im Gegensatz dazu zeigte das Thema `Politik` keinen signifikanten Unterschied zwischen Videos mit und ohne diese Zuordnung.\n",
    "\n",
    "<img src=\"../references/images/boxplot Politik_Aufrufe.JPG\" width=\"400\" alt=\"Boxplot Politik vs. Aufrufe\"/>\n",
    "\n",
    "- **Bewertung_Titel und Gestaltung_Thumbnail vs. durchschn. Wiedergabedauer**\n",
    "  - In den Streudiagrammen ein mäßiger Zusammenhang zwischen der Titelbewertung, den Thumnails mit der durchschnittlichen Wiedergabedauer festgestellt. Hier im Bild ist auch die Videolänge im Zusammenhang mit der durchschn. Wiedergabedauer zu sehen. Der Zusammenhang scheint jedoch logisch. Bis zu einem gewissen Grad sollte bei längeren Videos auch die Wiedergabedauer steigen. Dieser Zusammenhang dürfte irgendwo aber auch eine Peak haben. \n",
    "  \n",
    "<img src=\"../references/images/streudiagramme_Wiedergabedauer_Thumbnail_Titel_Videolaenge.JPG\" width=\"1000\" alt=\"Boxplot Politik vs. Aufrufe\"/>\n",
    "\n",
    "### **Erste Zusammenfassung:**\n",
    "Die bisherige Analyse hat gezeigt, dass die Merkmale im Datensatz sehr unterschiedlich strukturiert sind und nicht alle Prädiktoren gleich behandelt werden sollten. Durch eine gezielte Auswahl von Features und die Anwendung einer selektiven Skalierung kann das Modell stabilisiert werden. Zusätzliche Transformationen könnten die Analyseergebnisse verbessern und den Einfluss einzelner Prädiktoren verstärken. Die meisten Variablen werden in der Regressionsanalyse keine Rolle spielen, da sie nicht beeinflussbar sind, sondern Performance-Vaiablen darstellen. Diese sind sicherlich wichtig, um weitere Anaylsen zur Struktur der User und Verhalten durchzuführen.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Ergebnis Vor-Analyse**\n",
    "\n",
    "Die Entwicklung der Analysestrategie war ein iterativer Prozess, der durch mehrere wichtige Erkenntnisse geprägt wurde. Zu Beginn der Untersuchung wurden alle verfügbaren Prädiktoren einbezogen, wobei sich früh zeigte, dass die am stärksten beeinflussbaren Faktoren wie Thumbnail-Gestaltung und Titelbewertung überraschend geringe Korrelationen mit den Zielvariablen aufwiesen.\n",
    "\n",
    "Eine genauere Untersuchung der Daten offenbarte, dass diese schwachen Zusammenhänge teilweise durch die besondere Charakteristik von Live-Übertragungen verzerrt wurden. Live-Videos folgen grundsätzlich anderen Gesetzmäßigkeiten als reguläre Nachrichtenvideos: Sie werden oft über Breaking News oder wichtige Ereignisse automatisch als Startseiten-Empfehlung ausgespielt, was zu überdurchschnittlich hohen Klickraten führt - unabhängig von Thumbnail oder Titel. Zudem werden Live-Videos häufig mit standardisierten Thumbnails und Titeln versehen, da bei Breaking News die Zeit für aufwändige Optimierungen fehlt.\n",
    "\n",
    "**Warum Kategorie \"Live\" aus den Daten nehmen**\n",
    "\n",
    "Diese Erkenntnis führte zu dem Entschluss, Live-Videos aus der Hauptanalyse auszuschließen, um die tatsächlichen Effekte der beeinflussbaren Faktoren bei regulären Nachrichtenvideos besser isolieren zu können. Die verbleibenden schwachen bis moderaten Zusammenhänge zwischen Thumbnail-Gestaltung, Titelbewertung und Performance-Metriken deuten darauf hin, dass der Erfolg von YouTube-Videos im Nachrichtenbereich von einem komplexen Zusammenspiel verschiedener Faktoren abhängt, die über rein gestalterische Aspekte hinausgehen.\n",
    "\n",
    "**Ausreisseranalyse**\n",
    "\n",
    "Die anschließende Ausreißeranalyse bestätigte diese Vermutung: Erst nach der Bereinigung extremer Ausreißer, die oft durch externe Faktoren wie besondere Nachrichtenereignisse oder algorithmusbedingte Empfehlungsschübe entstehen, wurden die tatsächlichen Effekte der Gestaltungselemente statistisch signifikant nachweisbar. Dies unterstreicht die Notwendigkeit, bei der Analyse von YouTube-Metriken im Nachrichtenbereich sowohl die besonderen Charakteristika verschiedener Videoformate als auch externe Einflussfaktoren zu berücksichtigen.\n",
    "\n",
    "Diese Erkenntnisse führten zu einem verfeinerten Analyseansatz, der sich auf reguläre Nachrichtenvideos konzentriert und durch geeignete statistische Methoden wie die IQR-basierte Ausreißerbereinigung die subtileren Effekte der Gestaltungselemente besser herausarbeiten kann."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ich habe die EDA durch folgenden Code gestaltet:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "def remove_outliers(data, method='iqr', threshold=1.5):\n",
    "    \"\"\"\n",
    "    Entfernt Ausreißer aus einer Serie basierend auf verschiedenen Methoden.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    data : pandas Series\n",
    "        Zu bereinigende Daten\n",
    "    method : str\n",
    "        'iqr' für IQR-Methode\n",
    "        'zscore' für Z-Score Methode\n",
    "        'modified_zscore' für modifizierten Z-Score\n",
    "    threshold : float\n",
    "        Schwellenwert für die jeweilige Methode\n",
    "    \"\"\"\n",
    "    if method == 'iqr':\n",
    "        Q1 = data.quantile(0.25)\n",
    "        Q3 = data.quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "        lower_bound = Q1 - threshold * IQR\n",
    "        upper_bound = Q3 + threshold * IQR\n",
    "        return (data >= lower_bound) & (data <= upper_bound)\n",
    "    \n",
    "    elif method == 'zscore':\n",
    "        z_scores = np.abs(stats.zscore(data))\n",
    "        return z_scores < threshold\n",
    "    \n",
    "    elif method == 'modified_zscore':\n",
    "        median = data.median()\n",
    "        mad = stats.median_abs_deviation(data)\n",
    "        modified_z_scores = 0.6745 * (data - median) / mad\n",
    "        return np.abs(modified_z_scores) < threshold\n",
    "    \n",
    "    return pd.Series([True] * len(data))\n",
    "\n",
    "def flexible_analysis(X_data, y_data, target_variable, predictor_variables, \n",
    "                     outlier_method=None, outlier_threshold=1.5, output_dir='analysis_output'):\n",
    "    \"\"\"\n",
    "    Führt flexible Analyse mit optionaler Ausreißerbehandlung durch.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    X_data, y_data : DataFrames mit Prädiktoren und Zielvariablen\n",
    "    target_variable : str, Name der Zielvariable\n",
    "    predictor_variables : list, Liste der Prädiktorvariablen\n",
    "    outlier_method : str oder None, Methode der Ausreißerbehandlung\n",
    "    outlier_threshold : float, Schwellenwert für Ausreißerbehandlung\n",
    "    output_dir : str, Ausgabeverzeichnis\n",
    "    \"\"\"\n",
    "    \n",
    "    # Erstelle Ausgabeverzeichnis falls nicht vorhanden\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "    \n",
    "    # Filtere Live-Videos\n",
    "    #non_live_mask = X_data['theme_Live'] == 0\n",
    "    #X_filtered = X_data[non_live_mask]\n",
    "    #y_filtered = y_data[non_live_mask]\n",
    "    X_filtered = X_data\n",
    "    y_filtered = y_data\n",
    "\n",
    "    # Kombiniere Daten für die Analyse\n",
    "    analysis_data = pd.DataFrame()\n",
    "    analysis_data[target_variable] = y_filtered[target_variable]\n",
    "    for pred in predictor_variables:\n",
    "        analysis_data[pred] = X_filtered[pred]\n",
    "    \n",
    "    # Ausreißerbehandlung wenn gewünscht\n",
    "    if outlier_method:\n",
    "        print(f\"Ausreißerbehandlung mit Methode: {outlier_method}, Schwellenwert: {outlier_threshold}\")\n",
    "        initial_size = len(analysis_data)\n",
    "        mask = remove_outliers(analysis_data[target_variable], method=outlier_method, threshold=outlier_threshold)\n",
    "        analysis_data = analysis_data[mask]\n",
    "        print(f\"Entfernte Datenpunkte: {initial_size - len(analysis_data)} ({((initial_size - len(analysis_data))/initial_size*100):.1f}%)\")\n",
    "    \n",
    "    # Grundlegende statistische Analyse\n",
    "    print(f\"\\nAnalyse für Zielvariable: {target_variable}\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    print(\"\\nDeskriptive Statistik für Zielvariable:\")\n",
    "    print(analysis_data[target_variable].describe())\n",
    "    \n",
    "    # Analyse je Prädiktor\n",
    "    for pred in predictor_variables:\n",
    "        print(f\"\\nAnalyse für Prädiktor: {pred}\")\n",
    "        print(\"-\"*30)\n",
    "        \n",
    "        print(\"\\nDeskriptive Statistik:\")\n",
    "        print(analysis_data[pred].describe())\n",
    "        \n",
    "        # Für kategorische und metrische Variablen\n",
    "        is_categorical = analysis_data[pred].nunique() < 10\n",
    "        if is_categorical:\n",
    "            print(\"\\nGruppierte Statistiken:\")\n",
    "            grouped_stats = analysis_data.groupby(pred)[target_variable].agg(['mean', 'std', 'count'])\n",
    "            print(grouped_stats)\n",
    "            \n",
    "            # ANOVA\n",
    "            groups = [group for _, group in analysis_data.groupby(pred)[target_variable]]\n",
    "            if len(groups) >= 2:\n",
    "                f_stat, p_val = stats.f_oneway(*groups)\n",
    "                print(f\"\\nANOVA Test:\")\n",
    "                print(f\"F-Statistik: {f_stat:.4f}\")\n",
    "                print(f\"P-Wert: {p_val:.4f}\")\n",
    "                \n",
    "                # Effektstärken\n",
    "                categories = sorted(analysis_data[pred].unique())\n",
    "                print(\"\\nEffektstärken (Cohen's d):\")\n",
    "                for i in range(len(categories)):\n",
    "                    for j in range(i + 1, len(categories)):\n",
    "                        cat1 = categories[i]\n",
    "                        cat2 = categories[j]\n",
    "                        group1 = analysis_data[analysis_data[pred] == cat1][target_variable]\n",
    "                        group2 = analysis_data[analysis_data[pred] == cat2][target_variable]\n",
    "                        d = (group1.mean() - group2.mean()) / np.sqrt(\n",
    "                            ((group1.std()**2 + group2.std()**2) / 2))\n",
    "                        print(f\"Kategorie {cat1} vs {cat2}: {d:.4f}\")\n",
    "        else:\n",
    "            correlation = analysis_data[target_variable].corr(analysis_data[pred])\n",
    "            print(f\"\\nKorrelation mit Zielvariable: {correlation:.4f}\")\n",
    "            \n",
    "            # ANOVA (für metrische Prädiktoren)\n",
    "            groups = [group for _, group in analysis_data.groupby(pred)[target_variable]]\n",
    "            if len(groups) >= 2:\n",
    "                f_stat, p_val = stats.f_oneway(*groups)\n",
    "                print(f\"\\nANOVA Test:\")\n",
    "                print(f\"F-Statistik: {f_stat:.4f}\")\n",
    "                print(f\"P-Wert: {p_val:.4f}\")\n",
    "    \n",
    "    # Visualisierungen\n",
    "    fig, axes = plt.subplots(len(predictor_variables), 2, figsize=(12, 6*len(predictor_variables)))\n",
    "    if len(predictor_variables) == 1:\n",
    "        axes = axes.reshape(1, 2)\n",
    "    \n",
    "    for i, pred in enumerate(predictor_variables):\n",
    "        is_categorical = analysis_data[pred].nunique() < 10\n",
    "        \n",
    "        if is_categorical:\n",
    "            # Boxplot\n",
    "            sns.boxplot(x=pred, y=target_variable, data=analysis_data, ax=axes[i,0])\n",
    "            axes[i,0].set_title(f'Boxplot: {target_variable} nach {pred}')\n",
    "            axes[i,0].tick_params(axis='x', rotation=45)\n",
    "            \n",
    "            # Violinplot\n",
    "            sns.violinplot(x=pred, y=target_variable, data=analysis_data, ax=axes[i,1])\n",
    "            axes[i,1].set_title(f'Verteilung: {target_variable} nach {pred}')\n",
    "            axes[i,1].tick_params(axis='x', rotation=45)\n",
    "        else:\n",
    "            # Streudiagramm\n",
    "            sns.scatterplot(x=pred, y=target_variable, data=analysis_data, ax=axes[i,0])\n",
    "            axes[i,0].set_title(f'Streudiagramm: {target_variable} vs {pred}')\n",
    "            \n",
    "            # Regression\n",
    "            sns.regplot(x=pred, y=target_variable, data=analysis_data, ax=axes[i,1])\n",
    "            axes[i,1].set_title(f'Regression: {target_variable} vs {pred}')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return analysis_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Der dann durch drei Aufrufe nach den drei Zielvariablen Aufrufe, Klickrate und durchschn. Wiedergabedauer abgearbeitet wurde."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Beispielaufrufe:\n",
    "# Für Klickrate mit IQR-Methode\n",
    "flexible_analysis(X_train, y_train,\n",
    "                  target_variable='Klickrate der Impressionen (%)',\n",
    "                  predictor_variables=['Gestaltung_Thumbnail', 'Bewertung_Titel', 'video_length_seconds'],\n",
    "                  outlier_method='iqr',\n",
    "                  outlier_threshold=1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Für Wiedergabedauer mit modifiziertem Z-Score\n",
    "flexible_analysis(X_train, y_train,\n",
    "                  target_variable='durchschnittliche_wiedergabedauer',\n",
    "                  predictor_variables=['Gestaltung_Thumbnail', 'Bewertung_Titel', 'video_length_seconds'],\n",
    "                  outlier_method='modified_zscore',\n",
    "                  #outlier_method='iqr',                  \n",
    "                  outlier_threshold=3.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyse für Views\n",
    "# Für Aufrufe mit Z-Score\n",
    "flexible_analysis(X_train, y_train,\n",
    "                  target_variable='aufrufe',\n",
    "                  predictor_variables=['Gestaltung_Thumbnail', 'Bewertung_Titel', 'video_length_seconds'],\n",
    "                  outlier_method='zscore',\n",
    "                  outlier_threshold=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ergebnis EDA:\n",
    "Die Analyse der drei zentralen Metriken - Wiedergabedauer, Klickrate und Aufrufe - zeigt deutlich unterschiedliche Muster und Einflussfaktoren. Bei allen drei Analysen wurde die Ausreisser mit verschiedenen Methoden (IQR, ZScaler)\n",
    "\n",
    "**Durchschnittliche Wiedergabedauer:**\n",
    "Die durchschnittliche Wiedergabedauer beträgt 99,3 Sekunden mit einer beträchtlichen Streuung (Standardabweichung: 48,4 Sekunden). Die Thumbnail-Gestaltung zeigt einen hochsignifikanten Einfluss (p < 0.001), wobei besonders der Unterschied zwischen Kategorie 1 (75,2 Sek.) und den Kategorien 2 und 3 (108,4 bzw. 108,9 Sek.) auffällt. Die Effektstärken (Cohen's d) bestätigen diesen starken Effekt mit Werten von -0,74 und -0,80 zwischen Kategorie 1 und den anderen Kategorien. Bemerkenswert ist auch die starke positive Korrelation mit der Videolänge (r = 0,812), was einen klaren linearen Zusammenhang aufzeigt. Die Titelbewertung zeigt einen signifikanten, aber schwächeren Einfluss (p = 0,010), wobei interessanterweise niedrigere Bewertungen mit längeren Wiedergabezeiten assoziiert sind. Die Violin-Plots zeigen zudem eine zunehmende Konzentration der Verteilung bei höheren Thumbnail-Kategorien, was auf konsistentere Ergebnisse hindeutet.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Durchschnittliche Wiedergabedauer (Sekunden)**\n",
    "| Statistische Kennzahl | Wert |\n",
    "|----------------------|------|\n",
    "| Mittelwert | 99.30 |\n",
    "| Standardabweichung | 48.38 |\n",
    "| Minimum | 24.00 |\n",
    "| Maximum | 254.00 |\n",
    "| Median | 87.00 |\n",
    "| 25%-Quantil | 62.00 |\n",
    "| 75%-Quantil | 128.00 |\n",
    "\n",
    "*Nach Thumbnail-Kategorie:*\n",
    "| Kategorie | Mittelwert | Std.Abw. | n |\n",
    "|-----------|------------|----------|-----|\n",
    "| 1 | 75.22 | 39.11 | 227 |\n",
    "| 2 | 108.41 | 50.43 | 375 |\n",
    "| 3 | 108.88 | 44.84 | 214 |\n",
    "\n",
    "ANOVA: F = 42.98, p < 0.001\n",
    "\n",
    "*Nach Bewertung_Titel:*\n",
    "| Bewertung | Mittelwert | Std.Abw. | n |\n",
    "|-----------|------------|----------|-----|\n",
    "| 4.5 | 149.67 | 88.84 | 3 |\n",
    "| 5.5 | 104.00 | 55.35 | 6 |\n",
    "| 6.5 | 102.56 | 47.63 | 574 |\n",
    "| 7.5 | 93.26 | 50.59 | 129 |\n",
    "| 8.0 | 78.55 | 21.76 | 11 |\n",
    "| 8.5 | 88.10 | 47.73 | 93 |\n",
    "\n",
    "ANOVA: F = 3.02, p = 0.010\n",
    "\n",
    "*Korrelationen:*\n",
    "- Mit Video-Länge: r = 0.812\n",
    "- Mit Bewertung_Titel: r = -0.127 (berechnet aus den Gruppenmittelwerten)\n",
    "- Mit Gestaltung_Thumbnail: r = 0.301 (berechnet aus den Gruppenmittelwerten)\n",
    "\n",
    "Wichtige Erkenntnisse:\n",
    "1. Die Ausreißerbehandlung hat zu deutlich robusteren und klareren Ergebnissen geführt\n",
    "2. Der Einfluss der Thumbnail-Gestaltung ist noch deutlicher geworden:\n",
    "   - Klare Überlegenheit der Kategorien 2 und 3\n",
    "   - Praktisch kein Unterschied zwischen Kategorie 2 und 3\n",
    "3. Überraschender inverser Zusammenhang zwischen Titelbewertung und Wiedergabedauer\n",
    "\n",
    "\n",
    "<img src=\"../references/images/Grafische auswertung zielvariable Wiedergabedauer.JPG\" width=\"800\" alt=\"Grafische Analyse Klickrate\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Klickrate der Impressionen:**\n",
    "Die durchschnittliche Klickrate liegt bei 3,98% mit einer typischen Streuung (Standardabweichung: 2,14%). Die Verteilung zeigt eine realistische Spanne von 1% bis 10,05%, wobei der Median bei 3,52% liegt. Die Thumbnail-Gestaltung erweist sich als signifikanter Einflussfaktor (p = 0,038), wobei besonders die Kategorie 3 mit einem Durchschnitt von 4,24% positiv hervorsticht. Interessanterweise zeigt die Titelbewertung keinen statistisch signifikanten Einfluss (p = 0,737), obwohl die mittleren Bewertungskategorien (6,5 und 7,5) tendenziell etwas höhere Klickraten aufweisen. Die Videolänge hat einen sehr schwachen, leicht negativen Zusammenhang mit der Klickrate (r = -0,024), was darauf hindeutet, dass kürzere Videos minimal bessere Klickraten erzielen, dieser Effekt aber praktisch kaum relevant ist. Besonders auffällig ist die Konzentration der Daten im mittleren Bereich, was sich in der relativ geringen Differenz zwischen dem 25%- und 75%-Quantil (2,29% bis 5,34%) widerspiegelt.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Klickrate der Impressionen (%)**\n",
    "| Statistische Kennzahl | Wert |\n",
    "|----------------------|------|\n",
    "| Mittelwert | 3.98 |\n",
    "| Standardabweichung | 2.14 |\n",
    "| Minimum | 1.00 |\n",
    "| Maximum | 10.05 |\n",
    "| Median | 3.52 |\n",
    "| 25%-Quantil | 2.29 |\n",
    "| 75%-Quantil | 5.34 |\n",
    "\n",
    "*Nach Thumbnail-Kategorie:*\n",
    "| Kategorie | Mittelwert | Std.Abw. | n |\n",
    "|-----------|------------|----------|-----|\n",
    "| 1 | 4.04 | 2.14 | 228 |\n",
    "| 2 | 3.80 | 2.13 | 393 |\n",
    "| 3 | 4.24 | 2.13 | 226 |\n",
    "\n",
    "ANOVA: F = 3.27, p = 0.038\n",
    "\n",
    "*Nach Bewertung_Titel:*\n",
    "| Bewertung | Mittelwert | Std.Abw. | n |\n",
    "|-----------|------------|----------|-----|\n",
    "| 4.5 | 3.81 | 2.31 | 2 |\n",
    "| 5.5 | 3.29 | 1.79 | 8 |\n",
    "| 6.5 | 4.02 | 2.14 | 593 |\n",
    "| 7.5 | 4.05 | 2.18 | 133 |\n",
    "| 8.0 | 3.44 | 1.91 | 14 |\n",
    "| 8.5 | 3.80 | 2.12 | 97 |\n",
    "\n",
    "ANOVA: F = 0.55, p = 0.737\n",
    "\n",
    "*Korrelationen:*\n",
    "- Mit Video-Länge: r = -0.024\n",
    "- Mit Bewertung_Titel: r = -0.027 (berechnet aus den Gruppenmittelwerten)\n",
    "- Mit Gestaltung_Thumbnail: r = 0.048 (berechnet aus den Gruppenmittelwerten)\n",
    "\n",
    "Die Plots sahen ohne Ausreisser viel Spitzer aus. \n",
    "Schlussfolgerungen:\n",
    "1. Die Ausreißerbehandlung hat die Analyse geschärft und zu robusteren statistischen Ergebnissen geführt\n",
    "2. Der Einfluss der Thumbnail-Gestaltung ist nun statistisch signifikanter nachweisbar\n",
    "\n",
    "<img src=\"../references/images/Grafische auswertung zielvariable Klickrate.JPG\" width=\"800\" alt=\"Grafische Analyse durchschnittliche Wiedergabedauer\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Aufrufe:**\n",
    "Die Aufrufe zeigen eine sehr breite Streuung mit einem Mittelwert von 36.346 und einer hohen Standardabweichung von 53.476, was auf eine stark rechtsschiefe Verteilung hinweist. Der Median von 13.615 Aufrufen liegt deutlich unter dem Mittelwert, was diese Schiefe bestätigt. Die Thumbnail-Gestaltung zeigt einen knapp nicht signifikanten Einfluss (p = 0.056), wobei Kategorie 3 mit durchschnittlich 43.642 Aufrufen merklich höhere Werte erzielt als die Kategorien 1 und 2 (ca. 33.000). Bemerkenswert ist die sehr schwache Korrelation mit der Videolänge (r = 0.021), was darauf hindeutet, dass die Länge eines Videos praktisch keinen Einfluss auf die Aufrufzahlen hat. Die Titelbewertung zeigt keinen signifikanten Einfluss (p = 0.498), wobei die geringen Fallzahlen in einigen Bewertungskategorien die Aussagekraft einschränken. Die Violin-Plots verdeutlichen die extreme Streuung der Aufrufe über alle Kategorien hinweg, was auf den starken Einfluss externer Faktoren hindeutet.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Aufrufe**\n",
    "| Statistische Kennzahl | Wert |\n",
    "|----------------------|------|\n",
    "| Mittelwert | 36.346 |\n",
    "| Standardabweichung | 53.476 |\n",
    "| Minimum | 178 |\n",
    "| Maximum | 293.153 |\n",
    "| Median | 13.615 |\n",
    "| 25%-Quantil | 3.227 |\n",
    "| 75%-Quantil | 46.170 |\n",
    "\n",
    "*Nach Thumbnail-Kategorie:*\n",
    "| Kategorie | Mittelwert | Std.Abw. | n |\n",
    "|-----------|------------|----------|-----|\n",
    "| 1 | 33.176 | 50.445 | 229 |\n",
    "| 2 | 33.993 | 52.591 | 389 |\n",
    "| 3 | 43.642 | 57.401 | 225 |\n",
    "\n",
    "ANOVA: F = 2.89, p = 0.056\n",
    "\n",
    "*Nach Bewertung_Titel:*\n",
    "| Bewertung | Mittelwert | Std.Abw. | n |\n",
    "|-----------|------------|----------|-----|\n",
    "| 4.5 | 71.906 | 66.096 | 3 |\n",
    "| 5.5 | 42.450 | 87.460 | 8 |\n",
    "| 6.5 | 36.084 | 52.790 | 590 |\n",
    "| 7.5 | 41.410 | 58.746 | 133 |\n",
    "| 8.0 | 23.106 | 40.972 | 14 |\n",
    "| 8.5 | 31.198 | 47.741 | 95 |\n",
    "\n",
    "ANOVA: F = 0.87, p = 0.498\n",
    "\n",
    "*Korrelationen:*\n",
    "- Mit Video-Länge: r = 0.021\n",
    "- Mit Bewertung_Titel: r = -0.183 (berechnet aus den Gruppenmittelwerten)\n",
    "- Mit Gestaltung_Thumbnail: r = 0.097 (berechnet aus den Gruppenmittelwerten)\n",
    "\n",
    "Wichtige Erkenntnisse:\n",
    "1. Die Ausreißerbehandlung hat erstmals signifikante Effekte der Thumbnail-Gestaltung auf die Aufrufe sichtbar gemacht\n",
    "2. Die hohe Variabilität der Aufrufe bleibt bestehen, was auf starke externe Einflussfaktoren hindeutet\n",
    "3. Die Titelbewertung zeigt keinen klaren Zusammenhang mit den Aufrufzahlen\n",
    "\n",
    "<img src=\"../references/images/Grafische auswertung zielvariable aufrufe.JPG\" width=\"800\" alt=\"Grafische Analyse Aufrufe\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Ein besonders interessanter Aspekt ist die unterschiedliche Wirkung der Thumbnail-Gestaltung auf die verschiedenen Metriken: Während sie bei der Wiedergabedauer einen starken und bei der Klickrate einen moderaten Einfluss hat, scheint sie für die absolute Anzahl der Aufrufe kaum relevant zu sein. Dies könnte darauf hindeuten, dass gut gestaltete Thumbnails zwar das Engagement der Zuschauer fördern, die reine Reichweite aber von anderen Faktoren abhängt.\n",
    "\n",
    "Diese Erkenntnisse legen nahe, dass für die verschiedenen Erfolgskennzahlen unterschiedliche Optimierungsstrategien erforderlich sind und eine reine Fokussierung auf einzelne Gestaltungsaspekte nicht ausreicht, um den Gesamterfolg eines Videos zu gewährleisten."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Methodology"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Modellierungsansatz für  Regressionsanalyse\n",
    "Den besten Ansatz nach der EDA sehe ich in der durchschnittlichen Wiedergabedauer. Dazu habe ich auch noch die Variable Publishing_Date in Wochentag und Stunde aufgeschlüsselt. Hier könnte auch noch ein sinnvoller Prädiktor liegen. Im Code wird alles ine einem Durchlauf analysiert. Die Ausreisser werden eleminiert, Stunde und Wochentag extrahiert und auch eine Cross-Validation zwischen Trainings- und Validierungsdatensatz durchgeführt. Die Modelle werde ich später letzendlich mit den Testdatensatz endgültig auf Herz und Nieren prüfen. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hier der Code für eine Regressionsanalyse der durchscnittlichen Wiedergabedauer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "\n",
    "def load_and_filter_data():\n",
    "    \"\"\"Lädt die Pickle-Daten und filtert die relevanten Features\"\"\"\n",
    "    with open('../data/processed/processed_data.pkl', 'rb') as f:\n",
    "        data = pickle.load(f)\n",
    "\n",
    "    # Zeitliche Features aus publish_date extrahieren\n",
    "    for dataset in ['X_train', 'X_val', 'X_test']:\n",
    "        if 'publish_date' in data[dataset].columns:\n",
    "            # Konvertiere zu datetime mit deutschem Format\n",
    "            data[dataset]['publish_date'] = pd.to_datetime(data[dataset]['publish_date'], \n",
    "                                                         format='%d.%m.%Y %H:%M')\n",
    "            # Extrahiere Stunde und Wochentag\n",
    "            data[dataset]['publish_hour'] = data[dataset]['publish_date'].dt.hour\n",
    "            data[dataset]['publish_weekday'] = data[dataset]['publish_date'].dt.dayofweek\n",
    "    \n",
    "    # Liste der zu behaltenden Features\n",
    "    keep_features = [\n",
    "        'video_length_seconds',\n",
    "        'Gestaltung_Thumbnail',\n",
    "        'Bewertung_Titel',\n",
    "        'publish_hour',\n",
    "        'publish_weekday'\n",
    "    ]\n",
    "    \n",
    "    # Thema-Dummy-Variablen finden und hinzufügen\n",
    "    #theme_features = [col for col in data['X_train'].columns if col.startswith('theme_')]\n",
    "    # Thema-Dummy-Variablen finden und hinzufügen, aber ohne \"Live\"-Dummy, da ja auch keine Live-Videos mehr dabei sind\n",
    "    theme_features = [col for col in data['X_train'].columns if col.startswith('theme_') and not col.endswith('Live')]\n",
    "    keep_features.extend(theme_features)\n",
    "    \n",
    "    # Features filtern\n",
    "    X_train = data['X_train'][keep_features]\n",
    "    X_val = data['X_val'][keep_features]\n",
    "    X_test = data['X_test'][keep_features]\n",
    "    \n",
    "    # Zielvariable\n",
    "    y_train = data['y_train']['durchschnittliche_wiedergabedauer']\n",
    "    y_val = data['y_val']['durchschnittliche_wiedergabedauer']\n",
    "    y_test = data['y_test']['durchschnittliche_wiedergabedauer']\n",
    "    \n",
    "    print(\"Verwendete Features:\")\n",
    "    print(X_train.columns.tolist())\n",
    "    \n",
    "    return X_train, X_val, X_test, y_train, y_val, y_test\n",
    "\n",
    "def remove_outliers(X, y, method='iqr', threshold=1.5):\n",
    "    \"\"\"Entfernt Ausreißer basierend auf der gewählten Methode\"\"\"\n",
    "    if method == 'iqr':\n",
    "        Q1 = y.quantile(0.25)\n",
    "        Q3 = y.quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "        mask = ~((y < (Q1 - threshold * IQR)) | (y > (Q3 + threshold * IQR)))\n",
    "    elif method == 'zscore':\n",
    "        z_scores = np.abs(stats.zscore(y))\n",
    "        mask = z_scores < threshold\n",
    "    \n",
    "    X_clean = X[mask]\n",
    "    y_clean = y[mask]\n",
    "    \n",
    "    print(f\"Ausreißerbehandlung mit Methode: {method}, Schwellenwert: {threshold}\")\n",
    "    print(f\"Entfernte Datenpunkte: {len(y) - len(y_clean)} ({(1 - len(y_clean)/len(y))*100:.1f}%)\")\n",
    "    \n",
    "    return X_clean, y_clean\n",
    "\n",
    "def train_models(X, y):\n",
    "    \"\"\"Trainiert verschiedene Regressionsmodelle und vergleicht ihre Performance\"\"\"\n",
    "    models = {\n",
    "        'Linear Regression': LinearRegression(),\n",
    "        'Ridge Regression': Ridge(alpha=1.0),\n",
    "        'Lasso Regression': Lasso(alpha=1.0)\n",
    "    }\n",
    "    \n",
    "    results = {}\n",
    "    kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    \n",
    "    for name, model in models.items():\n",
    "        # Cross-Validation Scores\n",
    "        cv_scores = cross_val_score(model, X, y, cv=kfold, scoring='neg_mean_squared_error')\n",
    "        rmse_scores = np.sqrt(-cv_scores)\n",
    "        \n",
    "        # Modell auf gesamten Datensatz trainieren\n",
    "        model.fit(X, y)\n",
    "        y_pred = model.predict(X)\n",
    "        \n",
    "        results[name] = {\n",
    "            'model': model,\n",
    "            'cv_rmse_mean': rmse_scores.mean(),\n",
    "            'cv_rmse_std': rmse_scores.std(),\n",
    "            'r2_score': r2_score(y, y_pred),\n",
    "            'mae': mean_absolute_error(y, y_pred),\n",
    "            'predictions': y_pred\n",
    "        }\n",
    "        \n",
    "        # Feature Importance für Linear und Ridge Regression\n",
    "        if name in ['Linear Regression', 'Ridge Regression']:\n",
    "            results[name]['feature_importance'] = pd.DataFrame({\n",
    "                'feature': X.columns,\n",
    "                'importance': model.coef_\n",
    "            }).sort_values('importance', key=lambda x: abs(x), ascending=False)  # Sortierung nach absolutem Wert\n",
    "    \n",
    "    return results\n",
    "\n",
    "def analyze_residuals(y_true, y_pred, title=\"Residuenanalyse\"):\n",
    "    \"\"\"Führt eine detaillierte Residuenanalyse durch\"\"\"\n",
    "    residuals = y_true - y_pred\n",
    "    \n",
    "    # Plot erstellen\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "    fig.suptitle(title)\n",
    "    \n",
    "    # Residuen vs. vorhergesagte Werte\n",
    "    axes[0,0].scatter(y_pred, residuals, alpha=0.5)\n",
    "    axes[0,0].axhline(y=0, color='r', linestyle='--')\n",
    "    axes[0,0].set_xlabel('Vorhergesagte Werte')\n",
    "    axes[0,0].set_ylabel('Residuen')\n",
    "    axes[0,0].set_title('Residuen vs. Vorhergesage')\n",
    "    \n",
    "    # Q-Q Plot\n",
    "    stats.probplot(residuals, dist=\"norm\", plot=axes[0,1])\n",
    "    axes[0,1].set_title('Q-Q Plot')\n",
    "    \n",
    "    # Histogramm der Residuen\n",
    "    axes[1,0].hist(residuals, bins=30)\n",
    "    axes[1,0].set_xlabel('Residuen')\n",
    "    axes[1,0].set_ylabel('Häufigkeit')\n",
    "    axes[1,0].set_title('Verteilung der Residuen')\n",
    "    \n",
    "    # Tatsächliche vs. vorhergesagte Werte\n",
    "    axes[1,1].scatter(y_true, y_pred, alpha=0.5)\n",
    "    axes[1,1].plot([y_true.min(), y_true.max()], [y_true.min(), y_true.max()], 'r--')\n",
    "    axes[1,1].set_xlabel('Tatsächliche Werte')\n",
    "    axes[1,1].set_ylabel('Vorhergesagte Werte')\n",
    "    axes[1,1].set_title('Vorhersage vs. Realität')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Statistiken der Residuen\n",
    "    print(\"\\nStatistiken der Residuen:\")\n",
    "    print(f\"Mittelwert: {residuals.mean():.4f}\")\n",
    "    print(f\"Standardabweichung: {residuals.std():.4f}\")\n",
    "    print(f\"Schiefe: {stats.skew(residuals):.4f}\")\n",
    "    print(f\"Kurtosis: {stats.kurtosis(residuals):.4f}\")\n",
    "    \n",
    "    # Shapiro-Wilk Test auf Normalverteilung\n",
    "    _, p_value = stats.shapiro(residuals)\n",
    "    print(f\"\\nShapiro-Wilk Test p-Wert: {p_value:.4f}\")\n",
    "    \n",
    "    # Breusch-Pagan Test auf Homoskedastizität\n",
    "    _, p_value = stats.levene(residuals, y_pred)\n",
    "    print(f\"Breusch-Pagan Test p-Wert: {p_value:.4f}\")\n",
    "\n",
    "def main():\n",
    "    # 1) Daten laden und filtern\n",
    "    X_train, X_val, X_test, y_train, y_val, y_test = load_and_filter_data()\n",
    "    \n",
    "    # 2) Ausreißer entfernen\n",
    "    X_train_clean, y_train_clean = remove_outliers(X_train, y_train, method='iqr', threshold=1.5)\n",
    "    \n",
    "    # 3) Modelle trainieren\n",
    "    results = train_models(X_train_clean, y_train_clean)\n",
    "    \n",
    "    # 4) Ergebnisse ausgeben\n",
    "    print(\"\\nModellvergleich:\")\n",
    "    for name, result in results.items():\n",
    "        print(f\"\\n{name}:\")\n",
    "        print(f\"Cross-validated RMSE: {result['cv_rmse_mean']:.2f} (+/- {result['cv_rmse_std']:.2f})\")\n",
    "        print(f\"R² Score: {result['r2_score']:.4f}\")\n",
    "        print(f\"MAE: {result['mae']:.4f}\")\n",
    "        \n",
    "        if 'feature_importance' in result:\n",
    "            print(\"\\nFeature Importance:\")\n",
    "            print(result['feature_importance'])\n",
    "    \n",
    "    # 5) Bestes Modell auswählen\n",
    "    best_model_tuple = max(results.items(), key=lambda x: x[1]['r2_score'])  # CHANGED: rename to _tuple\n",
    "    best_model_name = best_model_tuple[0]   # z.B. \"Linear Regression\"\n",
    "    best_model_info = best_model_tuple[1]   # dictionary mit {'model':..., 'predictions':..., ...}\n",
    "\n",
    "    sklearn_model = best_model_info['model']  # ADDED: Hol dir das Modellobjekt\n",
    "    print(f\"\\nBestes Modell: {best_model_name}\")\n",
    "    \n",
    "    # 6) Validierung\n",
    "    final_predictions = sklearn_model.predict(X_val)\n",
    "    val_r2 = r2_score(y_val, final_predictions)\n",
    "    val_rmse = np.sqrt(mean_squared_error(y_val, final_predictions))\n",
    "    print(f\"\\nValidierungsergebnisse:\")\n",
    "    print(f\"R² Score: {val_r2:.4f}\")\n",
    "    print(f\"RMSE: {val_rmse:.2f}\")\n",
    "    \n",
    "    # 7) Residuenanalyse\n",
    "    analyze_residuals(y_train_clean, best_model_info['predictions'], \n",
    "                     title=f\"Residuenanalyse - {best_model_name}\")\n",
    "    \n",
    "    # 8) Intercept & Coefficients für lineare Modelle ausgeben - ADDED\n",
    "    if hasattr(sklearn_model, 'coef_') and hasattr(sklearn_model, 'intercept_'):\n",
    "        intercept = sklearn_model.intercept_\n",
    "        coefficients = sklearn_model.coef_\n",
    "        features = X_train_clean.columns\n",
    "        \n",
    "        print(\"\\n--- Lineare Modellformel / Koeffizienten ---\")\n",
    "        print(f\"Intercept: {intercept:.4f}\")\n",
    "        \n",
    "        for feat, coef_val in zip(features, coefficients):\n",
    "            print(f\"{feat}: {coef_val:.4f}\")\n",
    "    \n",
    "    # 9) Rückgabe (unverändert, nur best_model_tuple -> best_model_info['model'])\n",
    "    return results, sklearn_model  # CHANGED: Return the sklearn_model directly\n",
    "\n",
    "    \n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    results, best_model = main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Die Ergebnisse der ersten Regressionsanalyse (durchschnittliche Wiedergabedauer):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Modellvergleich**\n",
    "\n",
    "| Modell | RMSE (CV) | R² | MAE | Validation R² | Validation RMSE |\n",
    "|--------|-----------|-----|-----|---------------|-----------------|\n",
    "| Linear Regression | 27.18 (±2.96) | 0.6736 | 19.5105 | 0.7776 | 37.34 |\n",
    "| Ridge Regression | 27.18 (±2.96) | 0.6736 | 19.5095 | - | - |\n",
    "| Lasso Regression | 27.35 (±3.09) | 0.6672 | 19.6472 | - | - |\n",
    "\n",
    "**Residualstatistiken**\n",
    "\n",
    "| Metrik | Wert |\n",
    "|--------|------|\n",
    "| Mittelwert | -0.0000 |\n",
    "| Standardabweichung | 26.7346 |\n",
    "| Schiefe | -0.1785 |\n",
    "| Kurtosis | 3.3163 |\n",
    "\n",
    "**Modellkoeffizienten**\n",
    "\n",
    "| Parameter | Koeffizient |\n",
    "|-----------|-------------|\n",
    "| Intercept | 33.2770 |\n",
    "| video_length_seconds | 0.2053 |\n",
    "| Gestaltung_Thumbnail | 3.7091 |\n",
    "| Bewertung_Titel | 0.5780 |\n",
    "| publish_hour | 0.0340 |\n",
    "| publish_weekday | -0.0379 |\n",
    "| theme_Bilder | -12.0715 |\n",
    "| theme_Krieg | 10.7072 |\n",
    "| theme_Politik | 7.1267 |\n",
    "| theme_Sonstiges | -6.3158 |\n",
    "| theme_Wirtschaft | 0.5534 |\n",
    "\n",
    "**Feature Importance (sortiert nach absolutem Einfluss)**\n",
    "\n",
    "| Feature | Importance |\n",
    "|---------|------------|\n",
    "| theme_Bilder | -12.071480 |\n",
    "| theme_Krieg | 10.707203 |\n",
    "| theme_Politik | 7.126674 |\n",
    "| theme_Sonstiges | -6.315753 |\n",
    "| Gestaltung_Thumbnail | 3.709104 |\n",
    "| Bewertung_Titel | 0.577990 |\n",
    "| theme_Wirtschaft | 0.553356 |\n",
    "| video_length_seconds | 0.205289 |\n",
    "| publish_weekday | -0.037912 |\n",
    "| publish_hour | 0.033981 |\n",
    "\n",
    "\n",
    "<img src=\"../references/images/modell1wiedergabedauer.JPG\" width=\"800\" alt=\"Modell 1 druchschn. Wiedergabedauer\"/>\n",
    "\n",
    "\n",
    "**Zusammenfassung der wichtigsten Erkenntnisse**\n",
    "\n",
    "| Aspekt | Erkenntnis |\n",
    "|--------|------------|\n",
    "| Modellgüte | Moderate bis gute Erklärungskraft (R² = 0.67) |\n",
    "| Stärkste positive Prädiktoren | Kriegsthemen (+10.71s), Politik (+7.13s) |\n",
    "| Stärkste negative Prädiktoren | Bilderthemen (-12.07s), Sonstige Themen (-6.32s) |\n",
    "| Thumbnail-Effekt | Positiver Einfluss (+3.71s) |\n",
    "| Zeitliche Faktoren | Vernachlässigbarer Einfluss |\n",
    "| Modellannahmen | Verletzung der Normalverteilung und Homoskedastizität |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Analyse der linearen Regressionsmodelle**\n",
    "\n",
    "Die Regressionsanalyse für die Wiedergabedauer von YouTube-Videos zeigt interessante und praxisrelevante Ergebnisse. Das lineare Regressionsmodell erklärt etwa 67% der Varianz in den Trainingsdaten (R² = 0.6736) und zeigt sogar eine bessere Performance im Validierungsdatensatz (R² = 0.7776). Dies deutet auf ein robustes Modell hin, das nicht überangepasst ist.\n",
    "\n",
    "Besonders aufschlussreich sind die identifizierten Einflussfaktoren:\n",
    "- Thematische Ausrichtung hat den stärksten Einfluss: Kriegs- und Politikthemen führen zu deutlich längeren Wiedergabezeiten (+10.71s bzw. +7.13s), während Bilderthemen die Wiedergabedauer stark reduzieren (-12.07s)\n",
    "- Die Thumbnail-Gestaltung zeigt einen beachtlichen positiven Effekt (+3.71s)\n",
    "- Überraschend ist der geringe Einfluss zeitlicher Faktoren wie Veröffentlichungsstunde oder Wochentag\n",
    "\n",
    "Der Vergleich verschiedener Modellvarianten (Linear, Ridge, Lasso) zeigt sehr ähnliche Performancewerte, was die Stabilität der Ergebnisse unterstreicht. Die durchschnittliche Vorhersageabweichung von etwa 27 Sekunden (RMSE) ist im Kontext von YouTube-Videos als akzeptabel zu bewerten.\n",
    "\n",
    "Für die praktische Content-Strategie legen diese Ergebnisse nahe, dass der thematische Fokus und die Thumbnail-Gestaltung die wichtigsten Stellhebel für die Optimierung der Wiedergabedauer sind, während der Veröffentlichungszeitpunkt eine untergeordnete Rolle spielt. Die identifizierten Verletzungen der Modellannahmen sollten bei der Interpretation berücksichtigt werden, beeinträchtigen aber nicht die grundsätzlichen strategischen Implikationen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> REMOVE THE FOLLOWING TEXT\n",
    "\n",
    "This is where you will output the final model with any relevant model fit statistics.\n",
    "\n",
    "Describe the key results from the model.\n",
    "The goal is not to interpret every single variable in the model but rather to show that you are proficient in using the model output to address the research questions, using the interpretations to support your conclusions.\n",
    "\n",
    "Focus on the variables that help you answer the research question and that provide relevant context for the reader.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Forward Feature Selection**, (für ausgewählte Prädiktoren)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die Analyse konzentriert sich auf Faktoren, die bei der Erstellung von YouTube-Videos aktiv beeinflusst werden können. Dazu gehören:\n",
    "\n",
    "- Die Länge des Videos\n",
    "- Das gewählte Thema \n",
    "- Die Gestaltung des Titels\n",
    "- Die Gestaltung des Thumbnails\n",
    "- Der Veröffentlichungszeitpunkt (Wochentag und Uhrzeit)\n",
    "\n",
    "Um die Bedeutung dieser Faktoren systematisch zu untersuchen, wurde ein schrittweises Verfahren gewählt. Dabei startet die Analyse mit einem leeren Modell. In jedem Schritt wird dann jene Variable hinzugefügt, die die größte Verbesserung der Vorhersagegenauigkeit bringt. Diese Verbesserung wird durch Kreuzvalidierung überprüft, um zufällige Effekte auszuschließen.\n",
    "\n",
    "Dieser Ansatz hat den Vorteil, dass er die Faktoren nach ihrer Wichtigkeit ordnet. So lässt sich erkennen, welche Gestaltungselemente den stärksten Einfluss auf den Erfolg eines Videos haben. Andere Variablen, wie etwa bereits vorhandene Klickzahlen oder automatisch erfasste Metriken, wurden bewusst nicht berücksichtigt, da sie für die praktische Videogestaltung nicht relevant sind.\n",
    "\n",
    "Die Ergebnisse dieser Analyse ermöglichen es, Ressourcen gezielt dort einzusetzen, wo sie den größten Effekt haben. Wenn sich zum Beispiel zeigt, dass die Thumbnail-Gestaltung einen besonders starken Einfluss hat, während der Veröffentlichungszeitpunkt kaum eine Rolle spielt, können entsprechende Prioritäten in der Content-Produktion gesetzt werden.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Code für Forward Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import joblib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "from itertools import combinations\n",
    "\n",
    "#TARGET_VAR = \"durchschnittliche_wiedergabedauer\"  # Zielvariable ist durchschn. Wiedergabedauer\n",
    "#TARGET_VAR = \"aufrufe\"  # Aufrufe (views)\n",
    "TARGET_VAR = \"Klickrate der Impressionen (%)\"  # Klickrate der Impressionen\n",
    "\n",
    "def forward_feature_selection(X, y, \n",
    "                              scoring='r2', \n",
    "                              n_splits=5, \n",
    "                              random_state=42):\n",
    "    \"\"\"\n",
    "    Führt eine Vorwärtsselektion (Forward Feature Selection) durch,\n",
    "    basierend auf dem ausgewählten Scoring (Standard: R²).\n",
    "    \n",
    "    :param X: pd.DataFrame mit den rein beeinflussbaren Features\n",
    "    :param y: pd.Series oder np.array mit der Zielvariable\n",
    "    :param scoring: 'r2' oder 'neg_mean_squared_error'\n",
    "    :param n_splits: Anzahl K-Folds in der Cross-Validation\n",
    "    :param random_state: Zufallssamen für Reproduzierbarkeit\n",
    "    :return: \n",
    "       selected_features (List): Features in der Reihenfolge ihrer Aufnahme\n",
    "       best_models (Dict): Zwischenergebnisse \n",
    "           Key = Tuple(Features), Value = (Train_R2, Train_RMSE, Train_MAE, Modellobjekt)\n",
    "    \"\"\"\n",
    "    \n",
    "    all_features = list(X.columns)  # Alle möglichen Features, die DU beeinflussen kannst\n",
    "    \n",
    "    selected_features = []          # Start: Keine Features\n",
    "    remaining_features = set(all_features)\n",
    "    best_models = {}\n",
    "    \n",
    "    while remaining_features:\n",
    "        best_score = -np.inf\n",
    "        best_feature = None\n",
    "        \n",
    "        # Teste jedes Feature, das noch nicht ausgewählt ist\n",
    "        for feature in remaining_features:\n",
    "            current_features = selected_features + [feature]\n",
    "            X_sub = X[current_features]\n",
    "            \n",
    "            model = LinearRegression()\n",
    "            \n",
    "            # Cross-Validation (für R² oder neg_mean_squared_error)\n",
    "            kfold = KFold(n_splits=n_splits, shuffle=True, random_state=random_state)\n",
    "            \n",
    "            if scoring == 'r2':\n",
    "                cv_scores = cross_val_score(model, X_sub, y, cv=kfold, scoring='r2')\n",
    "                mean_score = cv_scores.mean()\n",
    "            elif scoring == 'neg_mean_squared_error':\n",
    "                cv_scores = cross_val_score(model, X_sub, y, cv=kfold, scoring='neg_mean_squared_error')\n",
    "                # Hier sind die Werte negativ, da MSE \"minimiert\" wird. \n",
    "                # Man könnte -mean_score nehmen, um \"maximieren\" zu simulieren. \n",
    "                # Für Forward-Selection reicht es oft, den Mittelwert direkt zu vergleichen.\n",
    "                mean_score = cv_scores.mean()\n",
    "            else:\n",
    "                raise ValueError(\"Bitte scoring='r2' oder 'neg_mean_squared_error' verwenden.\")\n",
    "            \n",
    "            # Wähle jenes Feature, das den besten (höchsten) Score liefert\n",
    "            if mean_score > best_score:\n",
    "                best_score = mean_score\n",
    "                best_feature = feature\n",
    "        \n",
    "        if best_feature is not None:\n",
    "            selected_features.append(best_feature)\n",
    "            remaining_features.remove(best_feature)\n",
    "            \n",
    "            # Trainiere ein finales Modell auf dem gesamten Datensatz (Train) mit den ausgewählten Features\n",
    "            X_sub = X[selected_features]\n",
    "            final_model = LinearRegression()\n",
    "            final_model.fit(X_sub, y)\n",
    "            \n",
    "            # Metriken auf dem gesamten Trainingsset (optional, zur Info)\n",
    "            y_pred = final_model.predict(X_sub)\n",
    "            train_r2 = r2_score(y, y_pred)\n",
    "            train_rmse = np.sqrt(mean_squared_error(y, y_pred))\n",
    "            train_mae = np.mean(np.abs(y - y_pred))\n",
    "            \n",
    "            best_models[tuple(selected_features)] = (train_r2, train_rmse, train_mae, final_model)\n",
    "            \n",
    "            print(f\"Feature hinzugefügt: {best_feature}. \"\n",
    "                  f\"Aktuelle Liste: {selected_features}. \"\n",
    "                  f\"(Train R²={train_r2:.4f}, RMSE={train_rmse:.2f}, MAE={train_mae:.2f})\")\n",
    "        else:\n",
    "            # Wenn kein Feature den Score steigert, brechen wir\n",
    "            break\n",
    "    \n",
    "    return selected_features, best_models\n",
    "\n",
    "def main():\n",
    "    # 1) Daten laden\n",
    "    with open('../data/processed/processed_data.pkl', 'rb') as f:\n",
    "        data = pickle.load(f)\n",
    "    \n",
    "    # Zeitliche Features aus publish_date extrahieren\n",
    "    for dataset in ['X_train', 'X_val']:\n",
    "        if 'publish_date' in data[dataset].columns:\n",
    "            data[dataset]['publish_date'] = pd.to_datetime(\n",
    "                data[dataset]['publish_date'], \n",
    "                format='%d.%m.%Y %H:%M'\n",
    "            )\n",
    "            data[dataset]['publish_hour'] = data[dataset]['publish_date'].dt.hour\n",
    "            data[dataset]['publish_weekday'] = data[dataset]['publish_date'].dt.dayofweek\n",
    "    \n",
    "    # 2) Trainings- und Validierungsdaten laden\n",
    "    X_train = data['X_train'].copy()\n",
    "    y_train = data['y_train'][TARGET_VAR].copy()\n",
    "    \n",
    "    X_val = data['X_val'].copy()\n",
    "    y_val = data['y_val'][TARGET_VAR].copy()\n",
    "    \n",
    "    # 3) Nur beeinflussbare Features (ohne theme_Live) behalten\n",
    "    candidate_features = [\n",
    "        'video_length_seconds',\n",
    "        'Gestaltung_Thumbnail',\n",
    "        'Bewertung_Titel',\n",
    "        'publish_hour',\n",
    "        'publish_weekday',\n",
    "        'theme_Bilder',\n",
    "        'theme_Krieg',\n",
    "        'theme_Politik',\n",
    "        'theme_Sonstiges',\n",
    "        'theme_Wirtschaft'\n",
    "    ]\n",
    "    \n",
    "    # Falls \"theme_Live\" existiert, ausschließen\n",
    "    if 'theme_Live' in X_train.columns:\n",
    "        X_train.drop(columns=['theme_Live'], inplace=True, errors='ignore')\n",
    "    if 'theme_Live' in X_val.columns:\n",
    "        X_val.drop(columns=['theme_Live'], inplace=True, errors='ignore')\n",
    "    \n",
    "    # Filter auf die Candidate-Features\n",
    "    X_train = X_train[candidate_features]\n",
    "    X_val = X_val[candidate_features]\n",
    "    \n",
    "    # 4) Forward Feature Selection (auf Trainingsdaten)\n",
    "    selected_feats, models_dict = forward_feature_selection(\n",
    "        X_train, \n",
    "        y_train, \n",
    "        scoring='r2',           # oder 'neg_mean_squared_error'\n",
    "        n_splits=5, \n",
    "        random_state=42\n",
    "    )\n",
    "    \n",
    "    print(\"\\n--- Vorwärtsselektion abgeschlossen ---\")\n",
    "    print(\"Ausgewählte Features (in Reihenfolge der Aufnahme):\")\n",
    "    for feat in selected_feats:\n",
    "        print(\"  \", feat)\n",
    "    \n",
    "    # 5) Bestes Modell anhand des höchsten Train-R²\n",
    "    best_key = max(models_dict.keys(), key=lambda k: models_dict[k][0])  # Sortiere nach R²\n",
    "    best_r2, best_rmse, best_mae, best_model = models_dict[best_key]\n",
    "    \n",
    "    # 6) Test des besten Modells auf dem Validierungsdatensatz\n",
    "    X_val_sub = X_val[list(best_key)]\n",
    "    y_val_pred = best_model.predict(X_val_sub)\n",
    "    \n",
    "    val_r2 = r2_score(y_val, y_val_pred)\n",
    "    val_rmse = np.sqrt(mean_squared_error(y_val, y_val_pred))\n",
    "    val_mae = mean_absolute_error(y_val, y_val_pred)\n",
    "    \n",
    "    print(\"\\n--- Validierungsergebnisse mit dem besten Modell ---\")\n",
    "    print(f\"Train R² = {best_r2:.4f}, Val R² = {val_r2:.4f}\")\n",
    "    print(f\"Train RMSE = {best_rmse:.2f}, Val RMSE = {val_rmse:.2f}\")\n",
    "    print(f\"Train MAE = {best_mae:.2f}, Val MAE = {val_mae:.2f}\")\n",
    "    \n",
    "    # 7) Ausgabe der Koeffizienten (optional)\n",
    "    coef_df = pd.DataFrame({\n",
    "        'Feature': list(best_key),\n",
    "        'Coefficient': best_model.coef_\n",
    "    })\n",
    "    print(\"\\nKoeffizienten des finalen Modells:\")\n",
    "    print(\"Intercept:\", best_model.intercept_)\n",
    "    print(coef_df)\n",
    "    \n",
    "    # -----------------------------------\n",
    "    # 8) MODEL & INFO SPEICHERN\n",
    "    # -----------------------------------\n",
    "    # Ordner \"models\" anlegen, falls nicht vorhanden\n",
    "    os.makedirs(\"../models\", exist_ok=True)\n",
    "    \n",
    "    # Model-Dateiname (z.B. best_model_durchschnittliche_wiedergabedauer.pkl)\n",
    "    model_filename = f\"../models/best_model_{TARGET_VAR}.pkl\"\n",
    "    joblib.dump(best_model, model_filename)\n",
    "    print(f\"\\nModell gespeichert in: {model_filename}\")\n",
    "    \n",
    "    # Wichtigste Kennzahlen & Parameter als JSON speichern\n",
    "    model_info = {\n",
    "        \"target_variable\": TARGET_VAR,\n",
    "        \"selected_features\": list(best_key),\n",
    "        \"train_r2\": round(best_r2, 4),\n",
    "        \"train_rmse\": round(best_rmse, 2),\n",
    "        \"train_mae\": round(best_mae, 2),\n",
    "        \"val_r2\": round(val_r2, 4),\n",
    "        \"val_rmse\": round(val_rmse, 2),\n",
    "        \"val_mae\": round(val_mae, 2),\n",
    "        \"coefficients\": {\n",
    "            \"Intercept\": round(best_model.intercept_, 4)\n",
    "        }\n",
    "    }\n",
    "    # Coefficients-Detail\n",
    "    for feat, coef_val in zip(best_key, best_model.coef_):\n",
    "        model_info[\"coefficients\"][feat] = round(float(coef_val), 4)\n",
    "    \n",
    "    # JSON-Dateiname (z.B. best_model_durchschnittliche_wiedergabedauer_info.json)\n",
    "    json_filename = f\"../models/best_model_{TARGET_VAR}_info.json\"\n",
    "    with open(json_filename, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(model_info, f, indent=2, ensure_ascii=False)\n",
    "    \n",
    "    print(f\"\\nModell-Informationen als JSON gespeichert in: {json_filename}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Modelle im Vergleich (Model 1 vs. Forward Selection)\n",
    "\n",
    "| Metrik | Ursprüngliches Modell | Modell nach Vorwärtsselektion |\n",
    "|--------|----------------------|------------------------------|\n",
    "| Train R² | 0.6736 | 0.8642 |\n",
    "| Val R² | 0.7776 | 0.6946 |\n",
    "| Train RMSE | 27.18 | 35.03 |\n",
    "| Val RMSE | 37.34 | 43.76 |\n",
    "| Train MAE | 19.51 | 22.38 |\n",
    "| Val MAE | - | 22.27 |\n",
    "\n",
    "**2. Wesentliche Unterschiede**\n",
    "\n",
    "***Modellperformance***\n",
    "- Das neue Modell zeigt eine deutlich bessere Performance auf den Trainingsdaten (R² = 0.8642 vs. 0.6736)\n",
    "- Allerdings ist die Validierungsperformance etwas schlechter (R² = 0.6946 vs. 0.7776)\n",
    "- Die Fehlerwerte (RMSE, MAE) sind beim neuen Modell leicht höher\n",
    "\n",
    "**Koeffizientenvergleich**\n",
    "\n",
    "| Feature | Ursprüngliches Modell | Neues Modell | Änderung |\n",
    "|---------|---------------------|--------------|----------|\n",
    "| Intercept | 33.277 | 16.814 | ↓ |\n",
    "| video_length_seconds | 0.205 | 0.243 | ↑ |\n",
    "| theme_Bilder | -12.072 | -13.146 | ↓ |\n",
    "| theme_Krieg | 10.707 | 7.968 | ↓ |\n",
    "| Gestaltung_Thumbnail | 3.709 | 4.944 | ↑ |\n",
    "| Bewertung_Titel | 0.578 | 2.269 | ↑↑ |\n",
    "| publish_hour | 0.034 | -0.063 | ↔ |\n",
    "| publish_weekday | -0.038 | 0.415 | ↑ |\n",
    "| theme_Wirtschaft | 0.553 | -2.529 | ↓↓ |\n",
    "\n",
    "**Praktische Implikationen**\n",
    "\n",
    " a) Bestätigte Erkenntnisse\n",
    "- Thematische Ausrichtung bleibt der wichtigste Einflussfaktor\n",
    "- Bilderthemen haben weiterhin den stärksten negativen Einfluss\n",
    "- Gestaltungselemente (Thumbnail, Titel) zeigen positive Effekte\n",
    "\n",
    " b) Neue Erkenntnisse\n",
    "- Stärkerer Einfluss der Titelgestaltung (Koeffizient vervierfacht)\n",
    "- Deutlichere Auswirkung des Wochentags\n",
    "- Wirtschaftsthemen zeigen nun einen negativen statt positiven Effekt\n",
    "\n",
    "**Empfehlungen für die Praxis**\n",
    "\n",
    "1. **Content-Strategie**\n",
    "   - Fokus auf Kriegs- und Politikthemen beibehalten (Risiko wenn Krieg vorbei, Politik wenig los)\n",
    "   - Bilderthemen strategisch einsetzen, aber nicht überstrapazieren\n",
    "   - Wirtschaftsthemen kritisch prüfen (Themen näher am User suchen)\n",
    "\n",
    "2. **Produktionsoptimierung**\n",
    "   - Verstärkter Fokus auf Titeloptimierung\n",
    "   - Weiterhin hohe Priorität für Thumbnail-Gestaltung\n",
    "   - Publikationszeitpunkt berücksichtigen, aber nicht überpriorisieren\n",
    "\n",
    "3. **Monitoring**\n",
    "   - Regelmäßige Überprüfung der Themenperformance\n",
    "   - A/B-Tests für Titel- und Thumbnail-Varianten\n",
    "   - Kontinuierliche Validierung der Modellvorhersagen\n",
    "\n",
    "Die Regressionsanalyse liefert trotz ihrer Limitationen wertvolle und praktisch anwendbare Erkenntnisse für die Content-Optimierung. Die Kombination beider Modelle erhöht die Verlässlichkeit der grundlegenden Schlussfolgerungen und identifiziert klare Handlungsprioritäten für die Content-Strategie."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discussion + Conclusion\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Letzter Vergleich der Modelle für alle Zielvariablen mit Train, Val- und Testdaten\n",
    "Dafür wurden die einzelnen Forward Slection Analyse im Ordner Models gespeichert. So können diese nun noch einmal mit den drei Sets verglichen werden. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pickle\n",
    "import joblib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "\n",
    "def main():\n",
    "    # 1) Ziele definieren: Du hast 3 Zielvariablen\n",
    "    target_vars = [\n",
    "        \"Klickrate der Impressionen (%)\",\n",
    "        \"durchschnittliche_wiedergabedauer\",\n",
    "        \"aufrufe\"\n",
    "    ]\n",
    "    \n",
    "    # 2) Daten laden (inkl. X_test, y_test)\n",
    "    with open('../data/processed/processed_data.pkl', 'rb') as f:\n",
    "        data = pickle.load(f)\n",
    "    \n",
    "    X_test = data['X_test'].copy()\n",
    "    y_test_data = data['y_test']  # DataFrame oder Series mit allen Zielspalten\n",
    "    \n",
    "    # Falls 'publish_date' oder 'theme_Live' etc. noch aufbereitet werden muss, hier tun:\n",
    "    if 'publish_date' in X_test.columns:\n",
    "        X_test['publish_date'] = pd.to_datetime(X_test['publish_date'], format='%d.%m.%Y %H:%M')\n",
    "        X_test['publish_hour'] = X_test['publish_date'].dt.hour\n",
    "        X_test['publish_weekday'] = X_test['publish_date'].dt.dayofweek\n",
    "    \n",
    "    if 'theme_Live' in X_test.columns:\n",
    "        X_test.drop(columns=['theme_Live'], inplace=True, errors='ignore')\n",
    "    \n",
    "    # 3) Ergebnisse sammeln\n",
    "    results_list = []  # Speichert alle Ergebnisse in einer Liste von Dicts\n",
    "    \n",
    "    for target in target_vars:\n",
    "        # a) JSON-Datei mit den Kennzahlen laden\n",
    "        json_path = f\"../models/best_model_{target}_info.json\"\n",
    "        if not os.path.exists(json_path):\n",
    "            print(f\"Warnung: {json_path} nicht gefunden. Überspringe {target}.\")\n",
    "            continue\n",
    "        \n",
    "        with open(json_path, \"r\", encoding=\"utf-8\") as jf:\n",
    "            model_info = json.load(jf)\n",
    "        \n",
    "        # b) Modell laden (pkl-Datei)\n",
    "        model_path = f\"../models/best_model_{target}.pkl\"\n",
    "        if not os.path.exists(model_path):\n",
    "            print(f\"Warnung: {model_path} nicht gefunden. Überspringe {target}.\")\n",
    "            continue\n",
    "        \n",
    "        best_model = joblib.load(model_path)\n",
    "        \n",
    "        # c) Benötigte Features laut JSON\n",
    "        selected_features = model_info.get(\"selected_features\", [])\n",
    "        \n",
    "        # d) Test-Zielwerte extrahieren\n",
    "        if target not in y_test_data.columns:\n",
    "            print(f\"Zielvariable '{target}' nicht in y_test_data. Überspringe.\")\n",
    "            continue\n",
    "        y_test = y_test_data[target].copy()\n",
    "        y_test_str = data['y_test'][target].astype(str)\n",
    "        y_test_str = y_test_str.str.replace(\",\", \".\")\n",
    "        y_test = y_test_str.astype(float)\n",
    "\n",
    "        # e) X_test nach den im Modell verwendeten Features filtern\n",
    "        X_test_sub = X_test[selected_features].copy()\n",
    "        \n",
    "        # f) Vorhersage auf dem Testset\n",
    "        y_test_pred = best_model.predict(X_test_sub)\n",
    "        \n",
    "        # g) Kennzahlen berechnen\n",
    "        test_r2 = r2_score(y_test, y_test_pred)\n",
    "        test_rmse = np.sqrt(mean_squared_error(y_test, y_test_pred))\n",
    "        test_mae = mean_absolute_error(y_test, y_test_pred)\n",
    "        \n",
    "        # h) Vergleich mit Train/Val aus model_info\n",
    "        train_r2 = model_info.get(\"train_r2\", None)\n",
    "        val_r2   = model_info.get(\"val_r2\", None)\n",
    "        train_rmse = model_info.get(\"train_rmse\", None)\n",
    "        val_rmse   = model_info.get(\"val_rmse\", None)\n",
    "        train_mae  = model_info.get(\"train_mae\", None)\n",
    "        val_mae    = model_info.get(\"val_mae\", None)\n",
    "        \n",
    "        # i) Speichere Zusammenfassung in Dict\n",
    "        results_list.append({\n",
    "            \"Zielvariable\": target,\n",
    "            \"Train R²\": train_r2,\n",
    "            \"Val R²\": val_r2,\n",
    "            \"Test R²\": round(test_r2, 4),\n",
    "            \"Train RMSE\": train_rmse,\n",
    "            \"Val RMSE\": val_rmse,\n",
    "            \"Test RMSE\": round(test_rmse, 2),\n",
    "            \"Train MAE\": train_mae,\n",
    "            \"Val MAE\": val_mae,\n",
    "            \"Test MAE\": round(test_mae, 2),\n",
    "            \"Features\": selected_features\n",
    "        })\n",
    "    \n",
    "    # 4) Ausgabe in schöner Tabellenform\n",
    "    if results_list:\n",
    "        results_df = pd.DataFrame(results_list)\n",
    "        print(\"\\n=== Zusammenfassung aller Modelle (Train/Val/Test) ===\")\n",
    "        print(results_df.to_string(index=False))\n",
    "    else:\n",
    "        print(\"Keine Ergebnisse. Wurden die JSON- und pkl-Dateien gefunden?\")\n",
    "        \n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gesamtanalyse der Regressionsmodelle\n",
    "\n",
    "## 1. Modellperformance im Überblick\n",
    "\n",
    "| Zielvariable | Set | R² | RMSE | MAE |\n",
    "|--------------|-----|-----|------|-----|\n",
    "| **Wiedergabedauer** | Train | 0.8642 | 35.03 | 22.38 |\n",
    "| | Val | 0.6946 | 43.76 | 22.27 |\n",
    "| | Test | 0.8471 | 33.62 | 23.00 |\n",
    "| **Klickrate** | Train | 0.0438 | 2.29 | 1.77 |\n",
    "| | Val | 0.0443 | 2.15 | 1.75 |\n",
    "| | Test | 0.0216 | 2.21 | 1.75 |\n",
    "| **Aufrufe** | Train | 0.0478 | 90393.92 | 44625.83 |\n",
    "| | Val | 0.0399 | 133565.28 | 50106.51 |\n",
    "| | Test | 0.0733 | 79979.54 | 44775.76 |\n",
    "\n",
    "\n",
    "<img src=\"../references/images/Last1.JPG\" width=\"600\" alt=\"Modelperformance nach Kategorie\"/>\n",
    "<img src=\"../references/images/Last2.JPG\" width=\"600\" alt=\"Modelperformance Vergleich\"/>\n",
    "<img src=\"../references/images/Last3.JPG\" width=\"600\" alt=\"Anpassung Forward Selection\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code für Grafikanzeige Modell-Performance Parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Plotting Style\n",
    "plt.style.use('default')\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "plt.rcParams['figure.figsize'] = [12, 6]\n",
    "\n",
    "# Feature Importance Daten\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': ['theme_Bilder', 'theme_Krieg', 'theme_Sonstiges', 'Gestaltung_Thumbnail', \n",
    "                'Bewertung_Titel', 'theme_Wirtschaft', 'video_length_seconds', \n",
    "                'publish_weekday', 'publish_hour'],\n",
    "    'original': [-12.072, 10.707, -6.316, 3.709, 0.578, 0.553, 0.205, -0.038, 0.034],\n",
    "    'selected': [-13.146, 7.968, -9.667, 4.944, 2.269, -2.529, 0.243, 0.415, -0.063]\n",
    "})\n",
    "\n",
    "# Sortieren nach absolutem Einfluss der selected Werte\n",
    "feature_importance = feature_importance.assign(\n",
    "    abs_selected=lambda x: abs(x['selected'])\n",
    ").sort_values('abs_selected', ascending=True)\n",
    "\n",
    "# Performance Metriken\n",
    "performance_metrics = pd.DataFrame({\n",
    "    'metric': ['Wiedergabedauer', 'Klickrate', 'Aufrufe'],\n",
    "    'train_r2': [0.8642, 0.0438, 0.0478],\n",
    "    'val_r2': [0.6946, 0.0443, 0.0399],\n",
    "    'test_r2': [0.8471, 0.0216, 0.0733]\n",
    "})\n",
    "\n",
    "# Forward Selection Progress\n",
    "forward_progress = pd.DataFrame({\n",
    "    'step': range(1, 10),\n",
    "    'feature': ['video_length_seconds', 'theme_Sonstiges', 'theme_Krieg', 'theme_Bilder',\n",
    "                'Bewertung_Titel', 'Gestaltung_Thumbnail', 'publish_hour', \n",
    "                'publish_weekday', 'theme_Wirtschaft'],\n",
    "    'train_r2': [0.2, 0.35, 0.48, 0.62, 0.71, 0.78, 0.82, 0.85, 0.86],\n",
    "    'val_r2': [0.19, 0.33, 0.45, 0.58, 0.64, 0.66, 0.68, 0.69, 0.69]\n",
    "})\n",
    "\n",
    "# Plotting\n",
    "fig, (ax1, ax2, ax3) = plt.subplots(3, 1, figsize=(15, 20))\n",
    "\n",
    "# 1. Feature Importance Vergleich\n",
    "feature_importance.plot(kind='barh', x='feature', y=['original', 'selected'], ax=ax1)\n",
    "ax1.set_title('Feature Importance Vergleich')\n",
    "ax1.set_xlabel('Koeffizient')\n",
    "ax1.set_ylabel('Feature')\n",
    "ax1.legend(['Original Modell', 'Forward Selection'])\n",
    "\n",
    "# 2. R² Performance Vergleich\n",
    "performance_metrics.plot(kind='bar', x='metric', y=['train_r2', 'val_r2', 'test_r2'], ax=ax2)\n",
    "ax2.set_title('R² Performance Vergleich')\n",
    "ax2.set_xlabel('Metrik')\n",
    "ax2.set_ylabel('R²')\n",
    "ax2.legend(['Train R²', 'Validation R²', 'Test R²'])\n",
    "\n",
    "# 3. Forward Selection Progress\n",
    "forward_progress.plot(x='step', y=['train_r2', 'val_r2'], marker='o', ax=ax3)\n",
    "ax3.set_title('Forward Selection Fortschritt')\n",
    "ax3.set_xlabel('Schritt')\n",
    "ax3.set_ylabel('R²')\n",
    "ax3.legend(['Train R²', 'Validation R²'])\n",
    "ax3.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Optional: Speichern der Grafik\n",
    "plt.savefig('regression_analysis_plots.png', dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 2. Zentrale Erkenntnisse\n",
    "\n",
    "### Wiedergabedauer\n",
    "- **Stärkste Performance**: R² zwischen 0.69 und 0.86\n",
    "- Sehr stabile MAE-Werte (~22-23 Sekunden)\n",
    "- Gute Generalisierung auf Testdaten (Test R² = 0.8471)\n",
    "\n",
    "### Klickrate\n",
    "- **Schwache Performance**: R² < 0.05 über alle Sets\n",
    "- Konsistente MAE-Werte (~1.75%)\n",
    "- Geringe Vorhersagekraft des Modells\n",
    "\n",
    "### Aufrufe\n",
    "- **Schwächste Performance**: R² < 0.08\n",
    "- Hohe RMSE-Werte (~80.000-130.000 Aufrufe)\n",
    "- Keine verlässliche Vorhersagekraft\n",
    "\n",
    "## 3. Praktische Implikationen\n",
    "\n",
    "### Für Content-Strategie\n",
    "1. **Wiedergabedauer**\n",
    "   - Gut vorhersagbar und steuerbar\n",
    "   - Fokus auf identifizierte Einflussfaktoren sinnvoll\n",
    "   - Verlässliche Basis für strategische Entscheidungen\n",
    "\n",
    "2. **Klickrate**\n",
    "   - Kaum durch betrachtete Faktoren beeinflussbar\n",
    "   - Vermutlich stärkerer Einfluss externer Faktoren\n",
    "   - Neue Prädiktoren oder alternative Modelle nötig\n",
    "\n",
    "3. **Aufrufe**\n",
    "   - Sehr schwer vorhersagbar\n",
    "   - Wahrscheinlich stark von viralen Effekten abhängig\n",
    "   - Fokus auf qualitative statt quantitative Optimierung\n",
    "\n",
    "### Für Datenanalyse\n",
    "1. **Modellierung**\n",
    "   - Nichtlineare Ansätze für Klickrate und Aufrufe prüfen\n",
    "   - Feature Engineering für bessere Prädiktion\n",
    "   - Zeitreihenaspekte berücksichtigen\n",
    "\n",
    "2. **Datenerhebung**\n",
    "   - Zusätzliche Features für Klickrate und Aufrufe sammeln\n",
    "   - Externe Faktoren (News, Trends) einbeziehen\n",
    "   - Interaktionseffekte untersuchen\n",
    "\n",
    "## 4. Empfehlungen\n",
    "\n",
    "### Kurzfristig\n",
    "1. Fokus auf Optimierung der Wiedergabedauer\n",
    "2. Kritische Überprüfung der Thumbnail- und Titelstrategie\n",
    "3. Realistische Erwartungen an Klickraten- und Aufrufvorhersagen\n",
    "\n",
    "### Mittelfristig\n",
    "1. Alternative Modellierungsansätze für Klickrate und Aufrufe\n",
    "2. Erweiterung der Datenerfassung\n",
    "3. A/B-Tests für Thumbnail- und Titelgestaltung\n",
    "\n",
    "### Langfristig\n",
    "1. Entwicklung eines hybriden Vorhersagemodells\n",
    "2. Integration von Trend- und Konkurrenzdaten\n",
    "3. Automatisierte Optimierungsstrategien\n",
    "\n",
    "## 5. Fazit\n",
    "Die Analyse zeigt deutlich, dass die Wiedergabedauer der am besten vorhersagbare und steuerbare Erfolgsfaktor ist. Klickraten und Aufrufe scheinen von komplexeren, möglicherweise externen Faktoren abzuhängen, die durch die aktuellen Modelle nicht ausreichend erfasst werden. Dies legt nahe, den Fokus der Content-Optimierung primär auf die Wiedergabedauer zu legen, während für Klickraten und Aufrufe alternative Analyse- und Optimierungsstrategien entwickelt werden sollten."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
